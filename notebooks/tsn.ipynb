{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dehghani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from util import constants\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "from util.models import MODELS\n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "import tensorflow_datasets as tfds\n",
    "from tfds_data.aff_nist import AffNist\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from distill.repsim_util import get_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_transformer_network(input_fmap, theta, out_dims=None, **kwargs):\n",
    "    # grab input dimensions\n",
    "    B = tf.shape(input_fmap)[0]\n",
    "    H = tf.shape(input_fmap)[1]\n",
    "    W = tf.shape(input_fmap)[2]\n",
    "\n",
    "    # reshape theta to (B, 2, 3)\n",
    "    theta = tf.reshape(theta, [B, 2, 3])\n",
    "\n",
    "    # generate grids of same size or upsample/downsample if specified\n",
    "    if out_dims:\n",
    "        out_H = out_dims[0]\n",
    "        out_W = out_dims[1]\n",
    "        batch_grids = affine_grid_generator(out_H, out_W, theta)\n",
    "    else:\n",
    "        batch_grids = affine_grid_generator(H, W, theta)\n",
    "\n",
    "    x_s = batch_grids[:, 0, :, :]\n",
    "    y_s = batch_grids[:, 1, :, :]\n",
    "\n",
    "    # sample input with grid to get output\n",
    "    out_fmap = bilinear_sampler(input_fmap, x_s, y_s)\n",
    "\n",
    "    return out_fmap\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    shape = tf.shape(x)\n",
    "    batch_size = shape[0]\n",
    "    height = shape[1]\n",
    "    width = shape[2]\n",
    "\n",
    "    batch_idx = tf.range(0, batch_size)\n",
    "    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = tf.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = tf.stack([b, y, x], 3)\n",
    "\n",
    "    return tf.gather_nd(img, indices)\n",
    "\n",
    "\n",
    "def affine_grid_generator(height, width, theta):\n",
    "    num_batch = tf.shape(theta)[0]\n",
    "\n",
    "    # create normalized 2D grid\n",
    "    x = tf.linspace(-1.0, 1.0, width)\n",
    "    y = tf.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = tf.meshgrid(x, y)\n",
    "\n",
    "    # flatten\n",
    "    x_t_flat = tf.reshape(x_t, [-1])\n",
    "    y_t_flat = tf.reshape(y_t, [-1])\n",
    "\n",
    "    # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "    ones = tf.ones_like(x_t_flat)\n",
    "    sampling_grid = tf.stack([x_t_flat, y_t_flat, ones])\n",
    "\n",
    "    # repeat grid num_batch times\n",
    "    sampling_grid = tf.expand_dims(sampling_grid, axis=0)\n",
    "    sampling_grid = tf.tile(sampling_grid, tf.stack([num_batch, 1, 1]))\n",
    "\n",
    "    # cast to float32 (required for matmul)\n",
    "    theta = tf.cast(theta, 'float32')\n",
    "    sampling_grid = tf.cast(sampling_grid, 'float32')\n",
    "\n",
    "    # transform the sampling grid - batch multiply\n",
    "    batch_grids = tf.matmul(theta, sampling_grid)\n",
    "    # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "    # reshape to (num_batch, H, W, 2)\n",
    "    batch_grids = tf.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, x, y):\n",
    "    \"\"\"\n",
    "    Performs bilinear sampling of the input images according to the\n",
    "    normalized coordinates provided by the sampling grid. Note that\n",
    "    the sampling is done identically for each channel of the input.\n",
    "    To test if the function works properly, output image should be\n",
    "    identical to input image when theta is initialized to identity\n",
    "    transform.\n",
    "    Input\n",
    "    -----\n",
    "    - img: batch of images in (B, H, W, C) layout.\n",
    "    - grid: x, y which is the output of affine_grid_generator.\n",
    "    Returns\n",
    "    -------\n",
    "    - out: interpolated images according to grids. Same size as grid.\n",
    "    \"\"\"\n",
    "    H = tf.shape(img)[1]\n",
    "    W = tf.shape(img)[2]\n",
    "    max_y = tf.cast(H - 1, 'int32')\n",
    "    max_x = tf.cast(W - 1, 'int32')\n",
    "    zero = tf.zeros([], dtype='int32')\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x = tf.cast(x, 'float32')\n",
    "    y = tf.cast(y, 'float32')\n",
    "    x = 0.5 * ((x + 1.0) * tf.cast(max_x-1, 'float32'))\n",
    "    y = 0.5 * ((y + 1.0) * tf.cast(max_y-1, 'float32'))\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = tf.cast(tf.floor(x), 'int32')\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(tf.floor(y), 'int32')\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "    x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "    y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "    y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = tf.cast(x0, 'float32')\n",
    "    x1 = tf.cast(x1, 'float32')\n",
    "    y0 = tf.cast(y0, 'float32')\n",
    "    y1 = tf.cast(y1, 'float32')\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1-x) * (y1-y)\n",
    "    wb = (x1-x) * (y-y0)\n",
    "    wc = (x-x0) * (y1-y)\n",
    "    wd = (x-x0) * (y-y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = tf.expand_dims(wa, axis=3)\n",
    "    wb = tf.expand_dims(wb, axis=3)\n",
    "    wc = tf.expand_dims(wc, axis=3)\n",
    "    wd = tf.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STN(tf.keras.layers.Layer):\n",
    "    def __init__(self, *inputs, **kwargs):\n",
    "        super(STN, self).__init__(*inputs, **kwargs)\n",
    "        \n",
    "        self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                       l2=0.000000002)\n",
    "        self.create_layer()\n",
    "    \n",
    "    def create_layer(self):\n",
    "        # params\n",
    "        n_fc = 6\n",
    "        \n",
    "        def init_bias(shape, dtype=None):\n",
    "            # identity transform\n",
    "            initial = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "            initial = initial.astype('float32').flatten()\n",
    "            return initial\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.localisation_net = tf.keras.layers.Dense(\n",
    "        n_fc, activation=None, use_bias=True, kernel_initializer='zeros',\n",
    "        bias_initializer=init_bias)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        \n",
    "        x = self.flat(inputs)\n",
    "        h_fc1 = self.localisation_net(x)\n",
    "        tf.print('h_fc1', '')\n",
    "        # spatial transformer layer\n",
    "        h_trans = spatial_transformer_network(inputs, h_fc1)\n",
    "        \n",
    "        return h_trans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "  def __init__(self, filters, kernel_size, activation='relu',*inputs, **kwargs):\n",
    "    super(ResnetBlock, self).__init__(*inputs, **kwargs)\n",
    "    self.filters = filters\n",
    "    self.kernel_size = kernel_size\n",
    "    self.activation = activation\n",
    "    self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                   l2=0.000000002)\n",
    "\n",
    "    self.create_layer()\n",
    "\n",
    "\n",
    "\n",
    "  def create_layer(self):\n",
    "    self.conv1 = tf.keras.layers.Conv2D(self.filters, self.kernel_size,\n",
    "                                        activation=self.activation,\n",
    "                                        padding='same',\n",
    "                                        kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv2D(self.filters, self.kernel_size,\n",
    "                                 activation=None,\n",
    "                                 padding='same',\n",
    "                                 kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.activation = tf.keras.layers.Activation('relu')\n",
    "\n",
    "  def call(self, inputs, training=None, **kwargs):\n",
    "    outputs = self.conv1(inputs, training=training, **kwargs)\n",
    "    outputs = self.batch_norm1(outputs,training=training, **kwargs)\n",
    "    outputs = self.conv2(outputs, training=training, **kwargs)\n",
    "    outputs = self.batch_norm2(outputs,training=training, **kwargs)\n",
    "    outputs = self.add([outputs, inputs],training=training, **kwargs)\n",
    "    outputs = self.activation(outputs, training=training, **kwargs)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(tf.keras.Model):\n",
    "  def __init__(self, hparams, scope='resnet', *inputs, **kwargs):\n",
    "    if 'cl_token' in kwargs:\n",
    "      del kwargs['cl_token']\n",
    "    super(Resnet, self).__init__(name=scope, *inputs, **kwargs)\n",
    "    self.scope = scope\n",
    "    self.hparams = hparams\n",
    "    self.model_name = '_'.join([self.scope,\n",
    "                                'h-' + str(self.hparams.hidden_dim),\n",
    "                                'rd-' + str(self.hparams.num_res_net_blocks),\n",
    "                                'hdrop-' + str(self.hparams.hidden_dropout_rate),\n",
    "                                'indrop-' + str(self.hparams.input_dropout_rate)])\n",
    "\n",
    "    self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                   l2=0.000000002)\n",
    "    self.create_layers()\n",
    "    self.rep_index = 1\n",
    "    self.rep_layer = -1\n",
    "\n",
    "\n",
    "  def create_layers(self):\n",
    "    self.stn1 = STN()\n",
    "    self.activation = tf.keras.layers.Activation('relu')\n",
    "\n",
    "    self.conv1 = tf.keras.layers.Conv2D(self.hparams.filters[0], self.hparams.kernel_size[0],\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv2D(self.hparams.filters[1], self.hparams.kernel_size[1],\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm3 = tf.keras.layers.BatchNormalization()\n",
    "    self.pool2 = tf.keras.layers.MaxPooling2D(self.hparams.pool_size)\n",
    "\n",
    "    self.resblocks = []\n",
    "    for i in range(self.hparams.num_res_net_blocks):\n",
    "      self.resblocks.append(ResnetBlock(self.hparams.filters[2], self.hparams.kernel_size[2]))\n",
    "\n",
    "    self.conv4 = tf.keras.layers.Conv2D(self.hparams.filters[3], self.hparams.kernel_size[3],\n",
    "                                        activation=None)\n",
    "    self.batch_norm4 = tf.keras.layers.BatchNormalization()\n",
    "    self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    self.dense = tf.keras.layers.Dense(self.hparams.hidden_dim, activation='relu')\n",
    "    self.dropout = tf.keras.layers.Dropout(self.hparams.hidden_dropout_rate)\n",
    "    self.project = tf.keras.layers.Dense(self.hparams.output_dim, activation=None)\n",
    "\n",
    "  def call(self, inputs, padding_symbol=None, training=None, **kwargs):\n",
    "    x = self.stn1(inputs, training=training, **kwargs)\n",
    "    x = self.conv1(x, training=training, **kwargs)\n",
    "    x = self.batch_norm2(x, training=training, **kwargs)\n",
    "    x = self.activation(x)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.conv2(x, training=training, **kwargs)\n",
    "    x = self.batch_norm3(x, training=training, **kwargs)\n",
    "    x = self.activation(x)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.pool2(x, training=training, **kwargs)\n",
    "    for i in range(self.hparams.num_res_net_blocks):\n",
    "      x = self.resblocks[i](x, training=training, **kwargs)\n",
    "      x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.conv4(x, training=training, **kwargs)\n",
    "    x = self.batch_norm4(x, training=training, **kwargs)\n",
    "    x = self.activation(x)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.avgpool(x, training=training, **kwargs)\n",
    "    x = self.dense(x, training=training, **kwargs)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "    outputs = self.project(x, training=training, **kwargs)\n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_dir='../tf_ckpts'\n",
    "task_name='affnist'\n",
    "task = TASKS[task_name](get_task_params(), data_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: rsnt_mnist1\n",
      "{'hidden_dim': 512, 'pool_size': 3, 'filters': [32, 32, 32, 32], 'kernel_size': [(3, 3), (3, 3), (3, 3), (3, 3)], 'hidden_dropout_rate': 0.2, 'input_dropout_rate': 0.0, 'num_res_net_blocks': 2}\n",
      "<util.model_configs.ResnetConfig object at 0x7f2610042550>\n"
     ]
    }
   ],
   "source": [
    "config={'exp_name':'test',\n",
    "    'model_config':'rsnt_mnist1',\n",
    "    'task_name':'affnist',\n",
    "    'model_name':'resnet',\n",
    "    'chkpt_dir':'../tf_ckpts',\n",
    "    'learning_rate': 0.001\n",
    "    }\n",
    "\n",
    "task = TASKS[config['task_name']](get_task_params(batch_size=16), data_dir='../data')\n",
    "\n",
    "hparams = get_model_params(task, config['model_name'], config['model_config'])\n",
    "print(hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 40, 40, 1) (16,)\n",
      "h_fc1 \n",
      "(16, 10)\n",
      "Model: \"resnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "stn_3 (STN)                  multiple                  9606      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           multiple                  320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           multiple                  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "resnet_block_4 (ResnetBlock) multiple                  18752     \n",
      "_________________________________________________________________\n",
      "resnet_block_5 (ResnetBlock) multiple                  18752     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           multiple                  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  16896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  5130      \n",
      "=================================================================\n",
      "Total params: 88,336\n",
      "Trainable params: 87,888\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for x,y in task.train_dataset:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "out = model(inputs=x, training=True)\n",
    "print(out.shape)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=task.get_loss_fn(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

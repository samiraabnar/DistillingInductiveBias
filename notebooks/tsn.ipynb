{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dehghani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from util import constants\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "from util.models import MODELS\n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "import tensorflow_datasets as tfds\n",
    "from tfds_data.aff_nist import AffNist\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from distill.repsim_util import get_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_transformer_network(input_fmap, theta, out_dims=None, **kwargs):\n",
    "    # grab input dimensions\n",
    "    B = tf.shape(input_fmap)[0]\n",
    "    H = tf.shape(input_fmap)[1]\n",
    "    W = tf.shape(input_fmap)[2]\n",
    "\n",
    "    # reshape theta to (B, 2, 3)\n",
    "    theta = tf.reshape(theta, [B, 2, 3])\n",
    "\n",
    "    # generate grids of same size or upsample/downsample if specified\n",
    "    if out_dims:\n",
    "        out_H = out_dims[0]\n",
    "        out_W = out_dims[1]\n",
    "        batch_grids = affine_grid_generator(out_H, out_W, theta)\n",
    "    else:\n",
    "        batch_grids = affine_grid_generator(H, W, theta)\n",
    "\n",
    "    x_s = batch_grids[:, 0, :, :]\n",
    "    y_s = batch_grids[:, 1, :, :]\n",
    "\n",
    "    # sample input with grid to get output\n",
    "    out_fmap = bilinear_sampler(input_fmap, x_s, y_s)\n",
    "\n",
    "    return out_fmap\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    shape = tf.shape(x)\n",
    "    batch_size = shape[0]\n",
    "    height = shape[1]\n",
    "    width = shape[2]\n",
    "\n",
    "    batch_idx = tf.range(0, batch_size)\n",
    "    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = tf.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = tf.stack([b, y, x], 3)\n",
    "\n",
    "    return tf.gather_nd(img, indices)\n",
    "\n",
    "\n",
    "def affine_grid_generator(height, width, theta):\n",
    "    num_batch = tf.shape(theta)[0]\n",
    "\n",
    "    # create normalized 2D grid\n",
    "    x = tf.linspace(-1.0, 1.0, width)\n",
    "    y = tf.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = tf.meshgrid(x, y)\n",
    "\n",
    "    # flatten\n",
    "    x_t_flat = tf.reshape(x_t, [-1])\n",
    "    y_t_flat = tf.reshape(y_t, [-1])\n",
    "\n",
    "    # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "    ones = tf.ones_like(x_t_flat)\n",
    "    sampling_grid = tf.stack([x_t_flat, y_t_flat, ones])\n",
    "\n",
    "    # repeat grid num_batch times\n",
    "    sampling_grid = tf.expand_dims(sampling_grid, axis=0)\n",
    "    sampling_grid = tf.tile(sampling_grid, tf.stack([num_batch, 1, 1]))\n",
    "\n",
    "    # cast to float32 (required for matmul)\n",
    "    theta = tf.cast(theta, 'float32')\n",
    "    sampling_grid = tf.cast(sampling_grid, 'float32')\n",
    "\n",
    "    # transform the sampling grid - batch multiply\n",
    "    batch_grids = tf.matmul(theta, sampling_grid)\n",
    "    # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "    # reshape to (num_batch, H, W, 2)\n",
    "    batch_grids = tf.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, x, y):\n",
    "    \"\"\"\n",
    "    Performs bilinear sampling of the input images according to the\n",
    "    normalized coordinates provided by the sampling grid. Note that\n",
    "    the sampling is done identically for each channel of the input.\n",
    "    To test if the function works properly, output image should be\n",
    "    identical to input image when theta is initialized to identity\n",
    "    transform.\n",
    "    Input\n",
    "    -----\n",
    "    - img: batch of images in (B, H, W, C) layout.\n",
    "    - grid: x, y which is the output of affine_grid_generator.\n",
    "    Returns\n",
    "    -------\n",
    "    - out: interpolated images according to grids. Same size as grid.\n",
    "    \"\"\"\n",
    "    H = tf.shape(img)[1]\n",
    "    W = tf.shape(img)[2]\n",
    "    max_y = tf.cast(H - 1, 'int32')\n",
    "    max_x = tf.cast(W - 1, 'int32')\n",
    "    zero = tf.zeros([], dtype='int32')\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x = tf.cast(x, 'float32')\n",
    "    y = tf.cast(y, 'float32')\n",
    "    x = 0.5 * ((x + 1.0) * tf.cast(max_x-1, 'float32'))\n",
    "    y = 0.5 * ((y + 1.0) * tf.cast(max_y-1, 'float32'))\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = tf.cast(tf.floor(x), 'int32')\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(tf.floor(y), 'int32')\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "    x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "    y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "    y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = tf.cast(x0, 'float32')\n",
    "    x1 = tf.cast(x1, 'float32')\n",
    "    y0 = tf.cast(y0, 'float32')\n",
    "    y1 = tf.cast(y1, 'float32')\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1-x) * (y1-y)\n",
    "    wb = (x1-x) * (y-y0)\n",
    "    wc = (x-x0) * (y1-y)\n",
    "    wd = (x-x0) * (y-y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = tf.expand_dims(wa, axis=3)\n",
    "    wb = tf.expand_dims(wb, axis=3)\n",
    "    wc = tf.expand_dims(wc, axis=3)\n",
    "    wd = tf.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STN(tf.keras.layers.Layer):\n",
    "    def __init__(self, *inputs, **kwargs):\n",
    "        super(STN, self).__init__(*inputs, **kwargs)\n",
    "        \n",
    "        self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                       l2=0.000000002)\n",
    "        self.create_layer()\n",
    "    \n",
    "    def create_layer(self):\n",
    "        # params\n",
    "        n_fc = 6\n",
    "        \n",
    "        def init_bias(shape, dtype=None):\n",
    "            # identity transform\n",
    "            initial = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "            initial = initial.astype('float32').flatten()\n",
    "            return initial\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.localisation_net = tf.keras.layers.Dense(\n",
    "        n_fc, activation=None, use_bias=True, kernel_initializer='zeros',\n",
    "        bias_initializer=init_bias)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        \n",
    "        x = self.flat(inputs)\n",
    "        h_fc1 = self.localisation_net(x)\n",
    "        # spatial transformer layer\n",
    "        h_trans = spatial_transformer_network(inputs, h_fc1)\n",
    "        \n",
    "        return h_trans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "  def __init__(self, filters, kernel_size, activation='relu',*inputs, **kwargs):\n",
    "    super(ResnetBlock, self).__init__(*inputs, **kwargs)\n",
    "    self.filters = filters\n",
    "    self.kernel_size = kernel_size\n",
    "    self.activation = activation\n",
    "    self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                   l2=0.000000002)\n",
    "\n",
    "    self.create_layer()\n",
    "\n",
    "\n",
    "\n",
    "  def create_layer(self):\n",
    "    self.conv1 = tf.keras.layers.Conv2D(self.filters, self.kernel_size,\n",
    "                                        activation=self.activation,\n",
    "                                        padding='same',\n",
    "                                        kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv2D(self.filters, self.kernel_size,\n",
    "                                 activation=None,\n",
    "                                 padding='same',\n",
    "                                 kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.activation = tf.keras.layers.Activation('relu')\n",
    "\n",
    "  def call(self, inputs, training=None, **kwargs):\n",
    "    outputs = self.conv1(inputs, training=training, **kwargs)\n",
    "    outputs = self.batch_norm1(outputs,training=training, **kwargs)\n",
    "    outputs = self.conv2(outputs, training=training, **kwargs)\n",
    "    outputs = self.batch_norm2(outputs,training=training, **kwargs)\n",
    "    outputs = self.add([outputs, inputs],training=training, **kwargs)\n",
    "    outputs = self.activation(outputs, training=training, **kwargs)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(tf.keras.Model):\n",
    "  def __init__(self, hparams, scope='resnet', *inputs, **kwargs):\n",
    "    if 'cl_token' in kwargs:\n",
    "      del kwargs['cl_token']\n",
    "    super(Resnet, self).__init__(name=scope, *inputs, **kwargs)\n",
    "    self.scope = scope\n",
    "    self.hparams = hparams\n",
    "    self.model_name = '_'.join([self.scope,\n",
    "                                'h-' + str(self.hparams.hidden_dim),\n",
    "                                'rd-' + str(self.hparams.num_res_net_blocks),\n",
    "                                'hdrop-' + str(self.hparams.hidden_dropout_rate),\n",
    "                                'indrop-' + str(self.hparams.input_dropout_rate)])\n",
    "\n",
    "    self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                   l2=0.000000002)\n",
    "    self.create_layers()\n",
    "    self.rep_index = 1\n",
    "    self.rep_layer = -1\n",
    "\n",
    "\n",
    "  def create_layers(self):\n",
    "    self.stn1 = STN()\n",
    "    self.activation = tf.keras.layers.Activation('relu')\n",
    "\n",
    "    self.conv1 = tf.keras.layers.Conv2D(self.hparams.filters[0], self.hparams.kernel_size[0],\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv2D(self.hparams.filters[1], self.hparams.kernel_size[1],\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=self.regularizer)\n",
    "    self.batch_norm3 = tf.keras.layers.BatchNormalization()\n",
    "    self.pool2 = tf.keras.layers.MaxPooling2D(self.hparams.pool_size)\n",
    "\n",
    "    self.resblocks = []\n",
    "    for i in range(self.hparams.num_res_net_blocks):\n",
    "      self.resblocks.append(ResnetBlock(self.hparams.filters[2], self.hparams.kernel_size[2]))\n",
    "\n",
    "    self.conv4 = tf.keras.layers.Conv2D(self.hparams.filters[3], self.hparams.kernel_size[3],\n",
    "                                        activation=None)\n",
    "    self.batch_norm4 = tf.keras.layers.BatchNormalization()\n",
    "    self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    self.dense = tf.keras.layers.Dense(self.hparams.hidden_dim, activation='relu')\n",
    "    self.dropout = tf.keras.layers.Dropout(self.hparams.hidden_dropout_rate)\n",
    "    self.project = tf.keras.layers.Dense(self.hparams.output_dim, activation=None)\n",
    "\n",
    "  def call(self, inputs, padding_symbol=None, training=None, **kwargs):\n",
    "    x = self.stn1(inputs, training=training, **kwargs)\n",
    "    x = self.conv1(x, training=training, **kwargs)\n",
    "    x = self.batch_norm2(x, training=training, **kwargs)\n",
    "    x = self.activation(x)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.conv2(x, training=training, **kwargs)\n",
    "    x = self.batch_norm3(x, training=training, **kwargs)\n",
    "    x = self.activation(x)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.pool2(x, training=training, **kwargs)\n",
    "    for i in range(self.hparams.num_res_net_blocks):\n",
    "      x = self.resblocks[i](x, training=training, **kwargs)\n",
    "      x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.conv4(x, training=training, **kwargs)\n",
    "    x = self.batch_norm4(x, training=training, **kwargs)\n",
    "    x = self.activation(x)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "\n",
    "    x = self.avgpool(x, training=training, **kwargs)\n",
    "    x = self.dense(x, training=training, **kwargs)\n",
    "    x = self.dropout(x, training=training, **kwargs)\n",
    "    outputs = self.project(x, training=training, **kwargs)\n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_dir='../tf_ckpts'\n",
    "task_name='affnist'\n",
    "task = TASKS[task_name](get_task_params(), data_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: rsnt_mnist1\n",
      "{'hidden_dim': 512, 'pool_size': 3, 'filters': [32, 32, 32, 32], 'kernel_size': [(3, 3), (3, 3), (3, 3), (3, 3)], 'hidden_dropout_rate': 0.2, 'input_dropout_rate': 0.0, 'num_res_net_blocks': 2}\n",
      "<util.model_configs.ResnetConfig object at 0x7f2b30c72190>\n"
     ]
    }
   ],
   "source": [
    "config={'exp_name':'test',\n",
    "    'model_config':'rsnt_mnist1',\n",
    "    'task_name':'affnist',\n",
    "    'model_name':'resnet',\n",
    "    'chkpt_dir':'../tf_ckpts',\n",
    "    'learning_rate': 0.001\n",
    "    }\n",
    "\n",
    "task = TASKS[config['task_name']](get_task_params(batch_size=16), data_dir='../data')\n",
    "\n",
    "hparams = get_model_params(task, config['model_name'], config['model_config'])\n",
    "print(hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 40, 40, 1) (16,)\n",
      "(16, 10)\n",
      "Model: \"resnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "stn_4 (STN)                  multiple                  9606      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           multiple                  320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           multiple                  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "resnet_block_6 (ResnetBlock) multiple                  18752     \n",
      "_________________________________________________________________\n",
      "resnet_block_7 (ResnetBlock) multiple                  18752     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           multiple                  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  16896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  5130      \n",
      "=================================================================\n",
      "Total params: 88,336\n",
      "Trainable params: 87,888\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for x,y in task.train_dataset:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "out = model(inputs=x, training=True)\n",
    "print(out.shape)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=task.get_loss_fn(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3125 steps, validate for 20000 steps\n",
      "Epoch 1/20\n",
      "3125/3125 - 137s - loss: 1.5411 - classification_loss: 1.5411 - sparse_categorical_accuracy: 0.4521 - val_loss: 2.2272 - val_classification_loss: 2.2272 - val_sparse_categorical_accuracy: 0.2747\n",
      "Epoch 2/20\n",
      "3125/3125 - 133s - loss: 1.6724 - classification_loss: 1.6724 - sparse_categorical_accuracy: 0.4110 - val_loss: 3.8626 - val_classification_loss: 3.8626 - val_sparse_categorical_accuracy: 0.1329\n",
      "Epoch 3/20\n",
      "3125/3125 - 134s - loss: 1.7754 - classification_loss: 1.7754 - sparse_categorical_accuracy: 0.3712 - val_loss: 3.3037 - val_classification_loss: 3.3037 - val_sparse_categorical_accuracy: 0.2101\n",
      "Epoch 4/20\n",
      "3125/3125 - 133s - loss: 1.8801 - classification_loss: 1.8801 - sparse_categorical_accuracy: 0.3296 - val_loss: 2.7884 - val_classification_loss: 2.7884 - val_sparse_categorical_accuracy: 0.1742\n",
      "Epoch 5/20\n",
      "3125/3125 - 135s - loss: 1.9907 - classification_loss: 1.9907 - sparse_categorical_accuracy: 0.2747 - val_loss: 2.8237 - val_classification_loss: 2.8237 - val_sparse_categorical_accuracy: 0.1758\n",
      "Epoch 6/20\n",
      "3125/3125 - 135s - loss: 2.1015 - classification_loss: 2.1015 - sparse_categorical_accuracy: 0.2209 - val_loss: 2.4172 - val_classification_loss: 2.4172 - val_sparse_categorical_accuracy: 0.1609\n",
      "Epoch 7/20\n",
      "3125/3125 - 135s - loss: 2.1527 - classification_loss: 2.1527 - sparse_categorical_accuracy: 0.1926 - val_loss: 2.8524 - val_classification_loss: 2.8524 - val_sparse_categorical_accuracy: 0.1498\n",
      "Epoch 8/20\n",
      "3125/3125 - 135s - loss: 2.1786 - classification_loss: 2.1786 - sparse_categorical_accuracy: 0.1786 - val_loss: 2.9529 - val_classification_loss: 2.9529 - val_sparse_categorical_accuracy: 0.1345\n",
      "Epoch 9/20\n",
      "3125/3125 - 134s - loss: 2.1921 - classification_loss: 2.1921 - sparse_categorical_accuracy: 0.1795 - val_loss: 2.2036 - val_classification_loss: 2.2036 - val_sparse_categorical_accuracy: 0.1848\n",
      "Epoch 10/20\n",
      "3125/3125 - 135s - loss: 2.1751 - classification_loss: 2.1751 - sparse_categorical_accuracy: 0.1976 - val_loss: 2.3202 - val_classification_loss: 2.3202 - val_sparse_categorical_accuracy: 0.1732\n",
      "Epoch 11/20\n",
      "3125/3125 - 135s - loss: 2.1735 - classification_loss: 2.1734 - sparse_categorical_accuracy: 0.1981 - val_loss: 2.3356 - val_classification_loss: 2.3356 - val_sparse_categorical_accuracy: 0.1280\n",
      "Epoch 12/20\n",
      "3125/3125 - 135s - loss: 2.2244 - classification_loss: 2.2244 - sparse_categorical_accuracy: 0.1619 - val_loss: 2.5233 - val_classification_loss: 2.5233 - val_sparse_categorical_accuracy: 0.1142\n",
      "Epoch 13/20\n",
      "3125/3125 - 135s - loss: 2.2382 - classification_loss: 2.2382 - sparse_categorical_accuracy: 0.1584 - val_loss: 5.5723 - val_classification_loss: 5.5723 - val_sparse_categorical_accuracy: 0.1210\n",
      "Epoch 14/20\n",
      "3125/3125 - 130s - loss: 2.2489 - classification_loss: 2.2489 - sparse_categorical_accuracy: 0.1507\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d47632e83845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_valid_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                   )\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=task.get_loss_fn(),\n",
    "              metrics=task.metrics())\n",
    "\n",
    "history = model.fit(task.train_dataset,\n",
    "                  epochs=20,\n",
    "                  steps_per_epoch=task.n_train_batches,\n",
    "                  validation_steps=task.n_valid_batches,\n",
    "                  validation_data=task.valid_dataset,\n",
    "                  verbose=2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

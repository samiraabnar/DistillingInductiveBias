{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dehghani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from util import constants\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "from util.models import MODELS\n",
    "from util.tasks import TASKS\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tfds_data.aff_nist import AffNist\n",
    "from calibration_util import *\n",
    "from notebook_utils import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def visualization(x, y,count,index):\n",
    "    x = np.reshape(x, (40, 40))\n",
    "    \n",
    "    plt.subplot(1,count,index)\n",
    "    plt.imshow(x, cmap=cm.Greys_r)\n",
    "    plt.title(y)\n",
    "    plt.axis('off')   \n",
    "\n",
    "def visualization_overlap(x0,x1, y0,y1,count,index):\n",
    "    r = np.reshape(x0, (40, 40))\n",
    "    g = np.reshape(x1, (40, 40))\n",
    "    b = np.zeros_like(r)\n",
    "    rgb = np.stack([r,g,b],-1)\n",
    "    \n",
    "    plt.subplot(1,count,index)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title('R:('+ str(y0)+','+str(y1)+')')\n",
    "    plt.axis('off')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_dir='../tf_ckpts'\n",
    "task_name = 'mnist40'\n",
    "mnist = TASKS[task_name](get_task_params(), data_dir='../data')\n",
    "\n",
    "chkpt_dir='../tf_ckpts'\n",
    "task_name = 'affnist'\n",
    "affnist = TASKS[task_name](get_task_params(), data_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10\n",
    "for x,y in affnist.test_dataset:\n",
    "    print(x.shape)\n",
    "    #visualization(x[1].numpy(),y[1].numpy(),1,1)\n",
    "    plt.imshow(x[0,...,0])\n",
    "    plt.show()\n",
    "    count -= 1\n",
    "    if count <= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10\n",
    "for x,y in mnist.valid_dataset:\n",
    "    print(x.shape)\n",
    "    #visualization(x[1].numpy(),y[1].numpy(),1,1)\n",
    "    plt.imshow(x[0,...,0])\n",
    "    plt.show()\n",
    "    count -= 1\n",
    "    if count <= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: ff_mnist2\n",
      "{}\n",
      "<util.model_configs.ModelConfig object at 0x7fe01c39a050>\n",
      "No checkpoint found ../tf_ckpts/mnist40/cl_vff_h-1024_d-3_hdrop-0.5_indrop-0.2_ff_mnist2_0.001_test\n"
     ]
    }
   ],
   "source": [
    "config={'exp_name':'test',\n",
    "    'model_config':'ff_mnist2',\n",
    "    'task_name':'mnist40',\n",
    "    'model_name':'cl_vff',\n",
    "    'chkpt_dir':'../tf_ckpts',\n",
    "    'learning_rate': 0.001\n",
    "    }\n",
    "\n",
    "task = TASKS[config['task_name']](get_task_params(batch_size=16), data_dir='../data')\n",
    "\n",
    "hparams = get_model_params(task, config['model_name'], config['model_config'])\n",
    "print(hparams)\n",
    "\n",
    "model, _ = get_model(config, task, hparams, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaFF(tf.keras.models.Sequential):\n",
    "  def __init__(self, hparams, scope=\"cl_vff\", *inputs, **kwargs):\n",
    "    if 'cl_token' in kwargs:\n",
    "      del kwargs['cl_token']\n",
    "\n",
    "    super(VanillaFF, self).__init__()\n",
    "    self.scope = scope\n",
    "    self.hparams = hparams\n",
    "\n",
    "    self.model_name = '_'.join([self.scope,\n",
    "                                'h-' + str(self.hparams.hidden_dim),\n",
    "                                'd-' + str(self.hparams.depth),\n",
    "                                'hdrop-' + str(self.hparams.hidden_dropout_rate),\n",
    "                                'indrop-' + str(self.hparams.input_dropout_rate)])\n",
    "\n",
    "    self.regularizer = tf.keras.regularizers.l1_l2(l1=0.00,\n",
    "                                                   l2=0.00001)\n",
    "    self.create_vars()\n",
    "    self.rep_index = 1\n",
    "    self.rep_layer = -1\n",
    "\n",
    "\n",
    "\n",
    "  def create_vars(self):\n",
    "    #self.batch_norm0 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv1 = tf.keras.layers.Conv2D(32, (3,3),\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=self.regularizer)\n",
    "    self.flat = tf.keras.layers.Flatten()\n",
    "    self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "    self.batch_norm.trainable = True\n",
    "    self.indrop = tf.keras.layers.Dropout(self.hparams.input_dropout_rate)\n",
    "\n",
    "    self.hidden_layers = []\n",
    "    self.hidden_batch_norms = []\n",
    "    self.hidden_dropouts = []\n",
    "    for i in np.arange(2):\n",
    "      self.hidden_layers.append(tf.keras.layers.Dense(self.hparams.hidden_dim,\n",
    "                                     activation='relu',\n",
    "                                     kernel_regularizer=self.regularizer))\n",
    "      self.hidden_batch_norms.append(tf.keras.layers.BatchNormalization())\n",
    "      self.hidden_batch_norms[i].trainable = True\n",
    "      self.hidden_dropouts.append(tf.keras.layers.Dropout(self.hparams.hidden_dropout_rate))\n",
    "\n",
    "    self.final_dense = tf.keras.layers.Dense(self.hparams.output_dim,\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "\n",
    "\n",
    "  def call(self, inputs, padding_symbol=None, training=None, **kwargs):\n",
    "    x = inputs # self.batch_norm0(inputs, training=training, **kwargs)\n",
    "    x = self.conv1(x, training=training, **kwargs)\n",
    "    x = self.flat(x, **kwargs)\n",
    "    x = self.batch_norm(x, training=training, **kwargs)\n",
    "    x = self.indrop(x, training=training, **kwargs)\n",
    "\n",
    "    for i in np.arange(2):\n",
    "      x = self.hidden_layers[i](x, training=training, **kwargs)\n",
    "      x = self.hidden_batch_norms[i](x, training=training, **kwargs)\n",
    "      x = self.hidden_dropouts[i](x, training=training, **kwargs)\n",
    "\n",
    "    logits = self.final_dense(x, training=training, **kwargs)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "  def detailed_call(self, inputs, padding_symbol=None, training=None, **kwargs):\n",
    "    layer_activations = []\n",
    "    x = self.flat(inputs, **kwargs)\n",
    "    x = self.batch_norm(x, training=training, **kwargs)\n",
    "    x = self.indrop(x, training=None, **kwargs)\n",
    "    layer_activations.append(x)\n",
    "\n",
    "    for i in np.arange(self.hparams.depth):\n",
    "      x = self.hidden_layers[i](x, training=None, **kwargs)\n",
    "      x = self.hidden_batch_norms[i](x, training=None, **kwargs)\n",
    "      x = self.hidden_dropouts[i](x, training=None, **kwargs)\n",
    "      layer_activations.append(x)\n",
    "\n",
    "    pnltimt = x\n",
    "    logits = self.final_dense(x, training=None, **kwargs)\n",
    "\n",
    "    return logits, pnltimt, layer_activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 40, 40, 1) (16,)\n",
      "Model: \"vanilla_ff_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_34 (Batc multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           multiple                  320       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc multiple                  184832    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             multiple                  47318016  \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             multiple                  1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc multiple                  4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc multiple                  4096      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             multiple                  10250     \n",
      "=================================================================\n",
      "Total params: 48,571,214\n",
      "Trainable params: 48,474,700\n",
      "Non-trainable params: 96,514\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VanillaFF(hparams)\n",
    "for x,y in task.train_dataset:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "model(inputs=x, training=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=task.get_loss_fn(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3750 steps, validate for 625 steps\n",
      "Epoch 1/10\n",
      "3750/3750 - 39s - loss: 0.5405 - classification_loss: 0.4357 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.3278 - val_classification_loss: 0.1726 - val_sparse_categorical_accuracy: 0.9481\n",
      "Epoch 2/10\n",
      "3750/3750 - 37s - loss: 0.5107 - classification_loss: 0.2876 - sparse_categorical_accuracy: 0.9155 - val_loss: 0.4100 - val_classification_loss: 0.1192 - val_sparse_categorical_accuracy: 0.9646\n",
      "Epoch 3/10\n",
      "3750/3750 - 37s - loss: 0.6335 - classification_loss: 0.2704 - sparse_categorical_accuracy: 0.9201 - val_loss: 87.6646 - val_classification_loss: 87.0887 - val_sparse_categorical_accuracy: 0.1137\n",
      "Epoch 4/10\n",
      "3750/3750 - 37s - loss: 0.7220 - classification_loss: 0.2560 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.5119 - val_classification_loss: 0.1056 - val_sparse_categorical_accuracy: 0.9686\n",
      "Epoch 5/10\n",
      "3750/3750 - 37s - loss: 0.6356 - classification_loss: 0.2276 - sparse_categorical_accuracy: 0.9320 - val_loss: 0.7172 - val_classification_loss: 0.3140 - val_sparse_categorical_accuracy: 0.8835\n",
      "Epoch 6/10\n",
      "3750/3750 - 37s - loss: 0.6807 - classification_loss: 0.2297 - sparse_categorical_accuracy: 0.9308 - val_loss: 0.5470 - val_classification_loss: 0.1092 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "3750/3750 - 37s - loss: 0.7499 - classification_loss: 0.2928 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.7847 - val_classification_loss: 0.1721 - val_sparse_categorical_accuracy: 0.9538\n",
      "Epoch 8/10\n",
      "3750/3750 - 37s - loss: 0.7729 - classification_loss: 0.2794 - sparse_categorical_accuracy: 0.9154 - val_loss: 0.6383 - val_classification_loss: 0.1882 - val_sparse_categorical_accuracy: 0.9566\n",
      "Epoch 9/10\n",
      "3750/3750 - 37s - loss: 0.6387 - classification_loss: 0.2263 - sparse_categorical_accuracy: 0.9315 - val_loss: 0.4982 - val_classification_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9705\n",
      "Epoch 10/10\n",
      "3750/3750 - 37s - loss: 0.5943 - classification_loss: 0.2110 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.5003 - val_classification_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=task.get_loss_fn(),\n",
    "              metrics=task.metrics())\n",
    "\n",
    "history = model.fit(task.train_dataset,\n",
    "                  epochs=10,\n",
    "                  steps_per_epoch=task.n_train_batches,\n",
    "                  validation_steps=task.n_valid_batches,\n",
    "                  validation_data=task.valid_dataset,\n",
    "                  verbose=2\n",
    "                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 20s 4ms/step - loss: 35.1139 - classification_loss: 34.7236 - sparse_categorical_accuracy: 0.1398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[35.11385690574646, 34.7236, 0.13975625]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(affnist.test_dataset, steps=affnist.n_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

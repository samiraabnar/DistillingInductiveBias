{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from util import constants\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "from util.models import MODELS\n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_exp_name='lisa_fd7'\n",
    "teacher_exp_name='0.001_lisa_offlineteacher_v1'\n",
    "teacher_config='lstm_drop31_v2'\n",
    "task_name = 'word_sv_agreement_lm'\n",
    "student_model='lm_gpt2'\n",
    "teacher_model='lm_lstm_shared_emb'\n",
    "student_config='very_big_gpt_v10'\n",
    "distill_config='pure_distill_4'\n",
    "distill_mode='offline'\n",
    "\n",
    "chkpt_dir='../tf_ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_exp_name='lisa_fd10'\n",
    "teacher_exp_name='0.001_lisa_offlineteacher_v1'\n",
    "teacher_config='lstm_drop31_v2'\n",
    "task_name = 'word_sv_agreement_lm'\n",
    "student_model='lm_lstm_shared_emb'\n",
    "teacher_model='lm_lstm_shared_emb'\n",
    "student_config='lstm_drop31_v2'\n",
    "distill_config='pure_distill_4'\n",
    "distill_mode='offline'\n",
    "\n",
    "chkpt_dir='../tf_ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_exp_name='lisa_fd8'\n",
    "teacher_exp_name='0.0001_lisa_offlineteacher_v1'\n",
    "teacher_config='very_big_gpt_v10'\n",
    "task_name = 'word_sv_agreement_lm'\n",
    "student_model='lm_gpt2'\n",
    "teacher_model='lm_gpt2'\n",
    "student_config='very_big_gpt_v10'\n",
    "distill_config='pure_distill_4'\n",
    "distill_mode='offline'\n",
    "\n",
    "chkpt_dir='../tf_ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_exp_name='lisa_fd9'\n",
    "teacher_exp_name='0.0001_lisa_offlineteacher_v1'\n",
    "teacher_config='very_big_gpt_v10'\n",
    "task_name = 'word_sv_agreement_lm'\n",
    "student_model='lm_lstm_shared_emb'\n",
    "teacher_model='lm_gpt2'\n",
    "student_config= 'lstm_drop31_v2'\n",
    "distill_config='pure_distill_4'\n",
    "distill_mode='offline'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab len:  10032\n"
     ]
    }
   ],
   "source": [
    "task_name = 'word_sv_agreement_lm'\n",
    "chkpt_dir='../tf_ckpts'\n",
    "task = TASKS[task_name](get_task_params(), data_dir='../data')\n",
    "cl_token = task.databuilder.sentence_encoder().encode(constants.bos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = MODELS[teacher_model](hparams=get_model_params(task, teacher_model, teacher_config), cl_token=cl_token)\n",
    "std_hparams=get_model_params(task, student_model, student_config)\n",
    "std_hparams.output_attentions = True\n",
    "std_hparams.output_embeddings = True\n",
    "student_model = MODELS[student_model](\n",
    "std_hparams, cl_token=cl_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ckpt_dir = os.path.join(chkpt_dir, task.name,\n",
    "                              '_'.join([distill_mode,distill_config,\n",
    "                                        \"teacher\", teacher_model.model_name, \n",
    "                                        teacher_config,\n",
    "                                        teacher_exp_name,\n",
    "                                       \"student\",student_model.model_name,\n",
    "                                        str(student_config),\n",
    "                                        student_exp_name]))\n",
    "print(\"student_checkpoint:\", student_ckpt_dir)\n",
    "\n",
    "student_ckpt = tf.train.Checkpoint(net=student_model)\n",
    "student_manager = tf.train.CheckpointManager(student_ckpt, student_ckpt_dir, max_to_keep=None)\n",
    "\n",
    "student_ckpt.restore(student_manager.latest_checkpoint)\n",
    "if student_manager.latest_checkpoint:\n",
    "  print(\"Restored student from {}\".format(student_manager.latest_checkpoint))\n",
    "\n",
    "student_model.compile(loss=task.get_loss_fn(), metrics=task.metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_ckpt_dir = os.path.join(chkpt_dir, task.name,\n",
    "                                  '_'.join([teacher_model.model_name, teacher_config,teacher_exp_name]))\n",
    "\n",
    "teacher_ckpt = tf.train.Checkpoint(net=teacher_model)\n",
    "teacher_manager = tf.train.CheckpointManager(teacher_ckpt, teacher_ckpt_dir, max_to_keep=None)\n",
    "\n",
    "teacher_ckpt.restore(teacher_manager.latest_checkpoint)\n",
    "if teacher_manager.latest_checkpoint:\n",
    "  print(\"Restored student from {}\".format(teacher_manager.latest_checkpoint))\n",
    "\n",
    "teacher_model.compile(loss=task.get_loss_fn(), metrics=task.metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = teacher_model.evaluate(task.train_dataset, steps=task.n_train_batches)\n",
    "valid = teacher_model.evaluate(task.valid_dataset, steps=task.n_valid_batches)\n",
    "test = teacher_model.evaluate(task.test_dataset, steps=task.n_test_batches)\n",
    "\n",
    "print(\"train:\", train)\n",
    "print(\"valid:\", valid)\n",
    "print(\"test:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = student_model.evaluate(task.train_dataset, steps=task.n_train_batches)\n",
    "valid = student_model.evaluate(task.valid_dataset, steps=task.n_valid_batches)\n",
    "test = student_model.evaluate(task.test_dataset, steps=task.n_test_batches)\n",
    "\n",
    "print(\"train:\", train)\n",
    "print(\"valid:\", valid)\n",
    "print(\"test:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: lstm_drop31_v2\n",
      "{'hidden_dim': 512, 'embedding_dim': 512, 'depth': 2, 'hidden_dropout_rate': 0.3, 'input_dropout_rate': 0.2}\n",
      "Restored student from ../tf_ckpts/word_sv_agreement_lm/lm_lstm_shared_emb_em-512_h-512_d-2_hdrop-0.3_indrop-0.2_lstm_drop31_v2_0.001_lisa_crs_fst_offlineteacher_v23/ckpt-60\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 4.0966 - batch_masked_sequence_loss: 4.0966 - masked_batch_perplexity: 60.3868 - masked_perplexity: 78.1307 - accuracy: 0.0730 - accuracy_top2: 0.0938 - accuracy_top5: 0.1203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.096584298610687,\n",
       " 4.0965834,\n",
       " 60.386765,\n",
       " 78.13074,\n",
       " 0.07295053,\n",
       " 0.093817,\n",
       " 0.120311886]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'model_name':'lm_lstm_shared_emb',\n",
    "            'model_config':'lstm_drop31_v2',\n",
    "            'learning_rate':0.001,\n",
    "            'exp_name':'lisa_crs_fst_offlineteacher_v23',\n",
    "            'chkpt_dir': '../tf_ckpts'\n",
    "    }\n",
    "hparams=get_model_params(task, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "model, ckpt = get_model(config, task, hparams, cl_token)\n",
    "\n",
    "train = model.evaluate(task.train_dataset, steps=task.n_train_batches)\n",
    "valid = model.evaluate(task.valid_dataset, steps=task.n_valid_batches)\n",
    "test = model.evaluate(task.test_dataset, steps=task.n_test_batches)\n",
    "\n",
    "print(\"train:\", train)\n",
    "print(\"valid:\", valid)\n",
    "print(\"test:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='lm_gpt2'\n",
    "model_config='big_gpt_v5'\n",
    "learning_rate=0.0001\n",
    "exp_name='lisa_offlineteacher_v3'\n",
    "task_name = 'word_sv_agreement_lm'\n",
    "chkpt_dir = '../tf_ckpts'\n",
    "\n",
    "task = TASKS[task_name](get_task_params(), data_dir='../data')\n",
    "\n",
    "cl_token = task.databuilder.sentence_encoder().encode(constants.bos)\n",
    "hparams=get_model_params(task, model_name, model_config)\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "model = MODELS[model_name](hparams=hparams, cl_token=cl_token)\n",
    "\n",
    "\n",
    "ckpt_dir = os.path.join(chkpt_dir,task.name,\n",
    "                        model.model_name+\"_\"+str(model_config)+\"_\"+str(learning_rate)+\"_\"+exp_name)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, ckpt_dir, max_to_keep=None)\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "  print(\"Restored student from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    " print(\"Initialized from scratch\")\n",
    " print(ckpt_dir)\n",
    "\n",
    "model.compile(loss=task.get_loss_fn(), metrics=task.metrics())\n",
    "\n",
    "\n",
    "\n",
    "train = model.evaluate(task.train_dataset, steps=task.n_train_batches)\n",
    "print(\"train:\", train)\n",
    "\n",
    "valid = model.evaluate(task.valid_dataset, steps=task.n_valid_batches)\n",
    "print(\"valid:\", valid)\n",
    "\n",
    "test = model.evaluate(task.test_dataset, steps=task.n_test_batches)\n",
    "print(\"test:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

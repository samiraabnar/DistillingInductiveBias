Vocab len:  10032
model config: small_gpt_v9
model config: small_lstm_v4
student_checkpoint: ../tf_ckpts/word_sv_agreement_vp/online_dstl_6_crs_slw_teacher_cl_lstm_em-256_h-256_d-2_hdrop-0.8_indrop-0.2_small_lstm_v4_af_tchr5_student_cl_bert_h-128_d-6_rdrop-0.4_adrop-0.6_indrop-0.2_small_gpt_v9_af_std5
Restored student from ../tf_ckpts/word_sv_agreement_vp/online_dstl_6_crs_slw_teacher_cl_lstm_em-256_h-256_d-2_hdrop-0.8_indrop-0.2_small_lstm_v4_af_tchr5_student_cl_bert_h-128_d-6_rdrop-0.4_adrop-0.6_indrop-0.2_small_gpt_v9_af_std5/ckpt-60
  1/100 [..............................] - ETA: 8:31 - loss: 0.0256 - classification_loss: 0.0080 - sparse_categorical_accuracy: 1.0000  7/100 [=>............................] - ETA: 1:09 - loss: 0.0132 - classification_loss: 0.0018 - sparse_categorical_accuracy: 1.0000 13/100 [==>...........................] - ETA: 35s - loss: 0.0136 - classification_loss: 0.0020 - sparse_categorical_accuracy: 1.0000  18/100 [====>.........................] - ETA: 24s - loss: 0.0153 - classification_loss: 0.0028 - sparse_categorical_accuracy: 1.0000 23/100 [=====>........................] - ETA: 18s - loss: 0.0142 - classification_loss: 0.0023 - sparse_categorical_accuracy: 1.0000 28/100 [=======>......................] - ETA: 13s - loss: 0.0865 - classification_loss: 0.0384 - sparse_categorical_accuracy: 0.9643 33/100 [========>.....................] - ETA: 11s - loss: 0.1290 - classification_loss: 0.0597 - sparse_categorical_accuracy: 0.9394 39/100 [==========>...................] - ETA: 8s - loss: 0.1121 - classification_loss: 0.0512 - sparse_categorical_accuracy: 0.9487  45/100 [============>.................] - ETA: 6s - loss: 0.1339 - classification_loss: 0.0621 - sparse_categorical_accuracy: 0.9556 51/100 [==============>...............] - ETA: 5s - loss: 0.1301 - classification_loss: 0.0602 - sparse_categorical_accuracy: 0.9608 56/100 [===============>..............] - ETA: 4s - loss: 0.1264 - classification_loss: 0.0584 - sparse_categorical_accuracy: 0.9643 62/100 [=================>............] - ETA: 3s - loss: 0.1367 - classification_loss: 0.0635 - sparse_categorical_accuracy: 0.9516 67/100 [===================>..........] - ETA: 2s - loss: 0.1317 - classification_loss: 0.0610 - sparse_categorical_accuracy: 0.9552 72/100 [====================>.........] - ETA: 2s - loss: 0.1235 - classification_loss: 0.0569 - sparse_categorical_accuracy: 0.9583 77/100 [======================>.......] - ETA: 1s - loss: 0.1162 - classification_loss: 0.0533 - sparse_categorical_accuracy: 0.9610 82/100 [=======================>......] - ETA: 1s - loss: 0.1103 - classification_loss: 0.0503 - sparse_categorical_accuracy: 0.9634 87/100 [=========================>....] - ETA: 0s - loss: 0.1084 - classification_loss: 0.0494 - sparse_categorical_accuracy: 0.9655 92/100 [==========================>...] - ETA: 0s - loss: 0.1103 - classification_loss: 0.0503 - sparse_categorical_accuracy: 0.9674 97/100 [============================>.] - ETA: 0s - loss: 0.1054 - classification_loss: 0.0479 - sparse_categorical_accuracy: 0.9691100/100 [==============================] - 6s 62ms/step - loss: 0.1045 - classification_loss: 0.0474 - sparse_categorical_accuracy: 0.9700
SpearmanrResult(correlation=0.2389191550462824, pvalue=0.3557315679984201)
(17,)
(17,)
(17,)
(17,)
###############Layer  0 #############
raw blankout
0.7409895172832541 0.2358207738254243
raw inputgrad
(17,) (17,)
-0.13432621195770697 0.38823521312379855
raw grad
(17,) (17,)
0.5229674258582918 0.3259305918224893
************joint blankout
0.3253138424111972 0.16691198569929072
joint grad
(17,) (17,)
0.2201106855561668 0.3246655404259956
joint inputgrad
(17,) (17,)
0.4282872298057549 0.3036410487894402
*************flow
0.3253138424111972 0.16691198569929072
flow grad
(17,) (17,)
0.2201106855561668 0.3246655404259956
flow inputgrad
(17,) (17,)
0.4282872298057549 0.3036410487894402
###############Layer  1 #############
raw blankout
0.4321012393526783 0.45714766938577406
raw inputgrad
(17,) (17,)
-0.16740611098627023 0.42534686024108886
raw grad
(17,) (17,)
0.34578592403896224 0.39071965002155495
************joint blankout
0.3582514665391678 0.19817333123542122
joint grad
(17,) (17,)
0.24543006927370248 0.32953214195691766
joint inputgrad
(17,) (17,)
0.41120895141288477 0.3186154866559503
*************flow
0.3944843867350329 0.19681508963327957
flow grad
(17,) (17,)
0.2649235065186056 0.3382921033897137
flow inputgrad
(17,) (17,)
0.38962103121899133 0.3320023132683358
###############Layer  2 #############
raw blankout
0.24886380402970937 0.5406443946956574
raw inputgrad
(17,) (17,)
-0.10138301336094473 0.45329799544833344
raw grad
(17,) (17,)
0.20536000302910945 0.44916856660633747
************joint blankout
0.4157715562832629 0.23307404839704923
joint grad
(17,) (17,)
0.2915007174024441 0.3338452439436092
joint inputgrad
(17,) (17,)
0.361110824566333 0.3536733267764003
*************flow
0.5162241201316128 0.26453140311301565
flow grad
(17,) (17,)
0.35577048900054886 0.3550055864270336
flow inputgrad
(17,) (17,)
0.2282973277770874 0.4279886116642085
###############Layer  3 #############
raw blankout
0.16809926073388093 0.5542464856214784
raw inputgrad
(17,) (17,)
-0.04356329625996857 0.4672134920613205
raw grad
(17,) (17,)
0.15851408538904554 0.4610898502099281
************joint blankout
0.47239357956657213 0.2577996885674364
joint grad
(17,) (17,)
0.3378011507509232 0.34049250753781013
joint inputgrad
(17,) (17,)
0.30283528909974733 0.3903537475798925
*************flow
0.5759743932120179 0.2672231435381795
flow grad
(17,) (17,)
0.41955451557423573 0.3535519021135343
flow inputgrad
(17,) (17,)
0.16721814536747337 0.4283540573017
###############Layer  4 #############
raw blankout
0.17654826759693482 0.531347921915482
raw inputgrad
(17,) (17,)
-0.04997487460595311 0.46551067282955083
raw grad
(17,) (17,)
0.17763547403391033 0.449483484352174
************joint blankout
0.5240194713292359 0.2745791308021946
joint grad
(17,) (17,)
0.3763725509365442 0.34491730551519445
joint inputgrad
(17,) (17,)
0.2433985439009383 0.4194050539968272
*************flow
0.6113414543279297 0.26238568504640636
flow grad
(17,) (17,)
0.4572058074650107 0.34653234061483273
flow inputgrad
(17,) (17,)
0.12989205563057435 0.4248695572041796
###############Layer  5 #############
raw blankout
0.19539877820083454 0.5105550071949736
raw inputgrad
(17,) (17,)
-0.05604831219458206 0.45749543334427917
raw grad
(17,) (17,)
0.22523110453488804 0.4494301924725971
************joint blankout
0.5630770049568539 0.2800676243604011
joint grad
(17,) (17,)
0.4038470942452374 0.3458038348965209
joint inputgrad
(17,) (17,)
0.19701966858379577 0.4341984744034066
*************flow
0.6353017841377426 0.2564130372985589
flow grad
(17,) (17,)
0.48267207576649285 0.33954270891166466
flow inputgrad
(17,) (17,)
0.10475081625297293 0.42092559996129475

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dehghani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime   # date stamp the log directory\n",
    "import json  # for saving and loading hyperparameters\n",
    "import os, sys, re\n",
    "import time\n",
    "\n",
    "import absl\n",
    "import absl.logging as logging\n",
    "from tf2_models.matrix_caps import *\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from util.models import MODELS \n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "gfile = tf.io.gfile\n",
    "flags = absl.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsConfig(object):\n",
    "  def __init__(self,\n",
    "               **kwargs):\n",
    "    self.output_dim = 10\n",
    "    self.A = 32\n",
    "    self.B = 32\n",
    "    self.C = 16\n",
    "    self.D = 16\n",
    "    self.epsilon = 1e-9\n",
    "    self.l2 = 0.0000002\n",
    "    self.final_lambda = 0.01\n",
    "    self.iter_routing = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spread_loss(scores, y, global_step):\n",
    "    \"\"\"Spread loss.\n",
    "\n",
    "    \"In order to make the training less sensitive to the initialization and \n",
    "    hyper-parameters of the model, we use “spread loss” to directly maximize the \n",
    "    gap between the activation of the target class (a_t) and the activation of the \n",
    "    other classes. If the activation of a wrong class, a_i, is closer than the \n",
    "    margin, m, to at then it is penalized by the squared distance to the margin.\"\n",
    "\n",
    "    See Hinton et al. \"Matrix Capsules with EM Routing\" equation (3).\n",
    "\n",
    "    Author:\n",
    "    Ashley Gritzman 19/10/2018  \n",
    "    Credit:\n",
    "    Adapted from Suofei Zhang's implementation on GitHub, \"Matrix-Capsules-\n",
    "    EM-Tensorflow\"\n",
    "    https://github.com/www0wwwjs1/Matrix-Capsules-EM-Tensorflow  \n",
    "    Args: \n",
    "    scores: \n",
    "      scores for each class \n",
    "      (batch_size, num_class)\n",
    "    y: \n",
    "      index of true class \n",
    "      (batch_size, 1)  \n",
    "    Returns:\n",
    "    loss: \n",
    "      mean loss for entire batch\n",
    "      (scalar)\n",
    "    \"\"\"\n",
    "  \n",
    "    batch_size = tf.shape(scores)[0]\n",
    "\n",
    "    # margin = 0.2 + .79 * tf.sigmoid(tf.minimum(10.0, step / 50000.0 - 4))\n",
    "    # where step is the training step. We trained with batch size of 64.\"\n",
    "    m_min = 0.2\n",
    "    m_delta = 0.79\n",
    "    m = (m_min \n",
    "         + m_delta * tf.sigmoid(tf.minimum(10.0, global_step / 50000.0 - 4)))\n",
    "\n",
    "    num_class = tf.shape(scores)[-1]\n",
    "\n",
    "    y = tf.one_hot(y, num_class, dtype=tf.float32)\n",
    "\n",
    "    # Get the score of the target class\n",
    "    # (64, 1, 5)\n",
    "    scores = tf.reshape(scores, shape=[batch_size, 1, num_class])\n",
    "    # (64, 5, 1)\n",
    "    y = tf.expand_dims(y, axis=2)\n",
    "    # (64, 1, 5)*(64, 5, 1) = (64, 1, 1)\n",
    "    at = tf.matmul(scores, y)\n",
    "\n",
    "    # Compute spread loss, paper eq (3)\n",
    "    loss = tf.math.square(tf.maximum(0., m - (at - scores)))\n",
    "\n",
    "    # Sum losses for all classes\n",
    "    # (64, 1, 5)*(64, 5, 1) = (64, 1, 1)\n",
    "    # e.g loss*[1 0 1 1 1]\n",
    "    loss = tf.matmul(loss, 1. - y)\n",
    "\n",
    "    # Compute mean\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1) (128,)\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir='../tf_ckpts'\n",
    "task_name='mnist'\n",
    "strategy = tf.distribute.MirroredStrategy(devices=['/gpu:0','/gpu:1','/gpu:2','/gpu:3'])\n",
    "\n",
    "with strategy.scope(): \n",
    "    task = TASKS[task_name](get_task_params(batch_size=128), data_dir='../data')\n",
    "    \n",
    "    \n",
    "for x,y in task.train_dataset:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope(): \n",
    "    loss = task.get_loss_fn()\n",
    "    optimizer = optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function kernel_tile at 0x7f14b1ede950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function kernel_tile at 0x7f14b1ede950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function kernel_tile at 0x7f14b1ede950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function kernel_tile at 0x7f14b1ede950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"matrix_caps\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  832       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  16896     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "conv_caps1 (ConvCaps)        multiple                  73760     \n",
      "_________________________________________________________________\n",
      "conv_caps2 (ConvCaps)        multiple                  36896     \n",
      "_________________________________________________________________\n",
      "class_caps (FcCaps)          multiple                  2580      \n",
      "=================================================================\n",
      "Total params: 132,024\n",
      "Trainable params: 132,022\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#example_x, example_y = next(iter(task.train_dataset))\n",
    "#outputs = model(example_x, training=True)\n",
    "    \n",
    "with strategy.scope():\n",
    "    model = MatrixCaps(CapsConfig())\n",
    "    out = model(x) #.build(input_shape=task.input_shape())\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 468 steps\n",
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 17 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 17 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 2163s 5s/step - loss: 1.8869 - sparse_categorical_accuracy: 0.9343\n",
      "Epoch 2/20\n",
      "468/468 [==============================] - 2138s 5s/step - loss: 1.8618 - sparse_categorical_accuracy: 0.9475\n",
      "Epoch 3/20\n",
      "468/468 [==============================] - 2143s 5s/step - loss: 1.8366 - sparse_categorical_accuracy: 0.9538\n",
      "Epoch 4/20\n",
      "399/468 [========================>.....] - ETA: 5:16 - loss: 1.8134 - sparse_categorical_accuracy: 0.9550"
     ]
    }
   ],
   "source": [
    "history = model.fit(task.train_dataset,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=task.n_train_batches)\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with strategy.scope():\n",
    "history = model.evaluate(task.test_dataset,\n",
    "                    steps=task.n_test_batches)\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

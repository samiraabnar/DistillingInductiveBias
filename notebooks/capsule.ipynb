{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dehghani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime   # date stamp the log directory\n",
    "import json  # for saving and loading hyperparameters\n",
    "import os, sys, re\n",
    "import time\n",
    "\n",
    "import absl\n",
    "import absl.logging as logging\n",
    "from tf2_models.matrix_caps import *\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from util.models import MODELS \n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "gfile = tf.io.gfile\n",
    "flags = absl.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsConfig(object):\n",
    "  def __init__(self,\n",
    "               **kwargs):\n",
    "    self.output_dim = 10\n",
    "    self.A = 64\n",
    "    self.B = 8\n",
    "    self.C = 16\n",
    "    self.D = 16\n",
    "    self.epsilon = 1e-9\n",
    "    self.l2 = 0.0000002\n",
    "    self.final_lambda = 0.01\n",
    "    self.iter_routing = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_loss(scores, y, global_step):\n",
    "    \"\"\"Spread loss.\n",
    "\n",
    "    \"In order to make the training less sensitive to the initialization and \n",
    "    hyper-parameters of the model, we use “spread loss” to directly maximize the \n",
    "    gap between the activation of the target class (a_t) and the activation of the \n",
    "    other classes. If the activation of a wrong class, a_i, is closer than the \n",
    "    margin, m, to at then it is penalized by the squared distance to the margin.\"\n",
    "\n",
    "    See Hinton et al. \"Matrix Capsules with EM Routing\" equation (3).\n",
    "\n",
    "    Author:\n",
    "    Ashley Gritzman 19/10/2018  \n",
    "    Credit:\n",
    "    Adapted from Suofei Zhang's implementation on GitHub, \"Matrix-Capsules-\n",
    "    EM-Tensorflow\"\n",
    "    https://github.com/www0wwwjs1/Matrix-Capsules-EM-Tensorflow  \n",
    "    Args: \n",
    "    scores: \n",
    "      scores for each class \n",
    "      (batch_size, num_class)\n",
    "    y: \n",
    "      index of true class \n",
    "      (batch_size, 1)  \n",
    "    Returns:\n",
    "    loss: \n",
    "      mean loss for entire batch\n",
    "      (scalar)\n",
    "    \"\"\"\n",
    "  \n",
    "    batch_size = tf.shape(scores)[0]\n",
    "\n",
    "    # margin = 0.2 + .79 * tf.sigmoid(tf.minimum(10.0, step / 50000.0 - 4))\n",
    "    # where step is the training step. We trained with batch size of 64.\"\n",
    "    m_min = 0.2\n",
    "    m_delta = 0.79\n",
    "    m = (m_min \n",
    "         + m_delta * tf.sigmoid(tf.minimum(10.0, global_step / 50000.0 - 4)))\n",
    "\n",
    "    num_class = tf.shape(scores)[-1]\n",
    "\n",
    "    y = tf.one_hot(y, num_class, dtype=tf.float32)\n",
    "\n",
    "    # Get the score of the target class\n",
    "    # (64, 1, 5)\n",
    "    scores = tf.reshape(scores, shape=[batch_size, 1, num_class])\n",
    "    # (64, 5, 1)\n",
    "    y = tf.expand_dims(y, axis=2)\n",
    "    # (64, 1, 5)*(64, 5, 1) = (64, 1, 1)\n",
    "    at = tf.matmul(scores, y)\n",
    "\n",
    "    # Compute spread loss, paper eq (3)\n",
    "    loss = tf.math.square(tf.maximum(0., m - (at - scores)))\n",
    "\n",
    "    # Sum losses for all classes\n",
    "    # (64, 1, 5)*(64, 5, 1) = (64, 1, 1)\n",
    "    # e.g loss*[1 0 1 1 1]\n",
    "    loss = tf.matmul(loss, 1. - y)\n",
    "\n",
    "    # Compute mean\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "orig = tfds.load('smallnorb', split=\"train\")\n",
    "dataset = orig.map(map_func=lambda x: (tf.cast(x['image'], tf.float32), tf.one_hot(x['label_category'],depth=10)),\n",
    "                                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.batch(2)\n",
    "x,y = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = tfds.load('smallnorb', split=\"train\")\n",
    "valid_dataset = valid_dataset.map(map_func=lambda x: (tf.cast(x['image'], tf.float32), tf.one_hot(x['label_category'],depth=10)),\n",
    "                                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixCaps(CapsConfig())\n",
    "outputs = model(x)\n",
    "print(outputs.shape)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(x)\n",
    "tf.print(outputs.shape)\n",
    "tf.print(y.shape)\n",
    "model.loss(y, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x.numpy(), y=y.numpy(),\n",
    "          epochs=1,\n",
    "          verbose=2\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are Numpy arrays)\n",
    "#x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "#x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x_train = x_train[...,None].astype('float32')\n",
    "x_test = x_test[...,None].astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "tf.print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir='../tf_ckpts'\n",
    "task_name='mnist'\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    task = TASKS[task_name](get_task_params(batch_size=512), data_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 28, 28, 1) (512,)\n"
     ]
    }
   ],
   "source": [
    "for x,y in task.train_dataset:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 10)\n",
      "Model: \"matrix_caps\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  1664      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  8320      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  520       \n",
      "_________________________________________________________________\n",
      "conv_caps1 (ConvCaps)        multiple                  18464     \n",
      "_________________________________________________________________\n",
      "conv_caps2 (ConvCaps)        multiple                  36896     \n",
      "_________________________________________________________________\n",
      "class_caps (FcCaps)          multiple                  2580      \n",
      "=================================================================\n",
      "Total params: 68,448\n",
      "Trainable params: 68,446\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = MatrixCaps(CapsConfig())\n",
    "    example_x, example_y = next(iter(task.train_dataset))\n",
    "    outputs = model(example_x, training=True)\n",
    "    print(outputs.shape)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 17 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 17 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 422s 4s/step - loss: 1.8436 - sparse_categorical_accuracy: 0.9432 - val_loss: 1.8303 - val_sparse_categorical_accuracy: 0.9503\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 429s 4s/step - loss: 1.8230 - sparse_categorical_accuracy: 0.9487 - val_loss: 1.8129 - val_sparse_categorical_accuracy: 0.9548\n",
      "Epoch 3/10\n",
      " 12/117 [==>...........................] - ETA: 5:12 - loss: 1.8137 - sparse_categorical_accuracy: 0.9484"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    history = model.fit(task.train_dataset,\n",
    "                        epochs=10,\n",
    "                        steps_per_epoch=task.n_train_batches,\n",
    "                        validation_data=task.valid_dataset,\n",
    "                        validation_steps=task.n_valid_batches)\n",
    "\n",
    "    print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

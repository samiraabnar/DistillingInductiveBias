{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dehghani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from util import constants\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "from util.models import MODELS\n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "from distill.repsim_util import *\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "chkpt_dir='../tf_ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown split \"train\". Should be one of [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-041e6df91d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sst2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTASKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_task_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcl_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lm1b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codes/InDist/tasks/sst.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task_params, name, data_dir)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                 \u001b[0mbuilder_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSst2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                 output_padding=False)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codes/InDist/tasks/task.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task_params, num_replicas_in_sync, builder_cls, name, data_dir, output_padding)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_padding_symbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codes/InDist/tasks/task.py\u001b[0m in \u001b[0;36msetup_datasets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_train_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_valid_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_test_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_datasets/core/splits.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    584\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m           \u001b[0msplit_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m           \u001b[0minstruction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m       )\n\u001b[1;32m    588\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mSubSplitInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[0;34m(name, split_infos, instruction)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Create the absolute instruction (per split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m   \u001b[0mabsolute_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   return _make_file_instructions_from_absolutes(\n",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mto_absolute\u001b[0;34m(self, name2len)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \"\"\"\n\u001b[1;32m    546\u001b[0m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0;32m--> 547\u001b[0;31m             for rel_instr in self._relative_instructions]\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \"\"\"\n\u001b[1;32m    546\u001b[0m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0;32m--> 547\u001b[0;31m             for rel_instr in self._relative_instructions]\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/reflect/lib/python3.7/site-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m_rel_to_abs_instr\u001b[0;34m(rel_instr, name2len)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname2len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     raise ValueError('Unknown split \"{}\". Should be one of {}.'.format(\n\u001b[0;32m--> 392\u001b[0;31m         split, list(name2len)))\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname2len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0mfrom_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_instr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown split \"train\". Should be one of []."
     ]
    }
   ],
   "source": [
    "task1 = 'sst2'\n",
    "task1 = TASKS[task1](get_task_params(), data_dir='../data')\n",
    "cl_token = task1.sentence_encoder().encode(constants.bos)\n",
    "\n",
    "task2 = 'lm1b'\n",
    "task2 = TASKS[task2](get_task_params(), data_dir='../data')\n",
    "cl_token = task2.sentence_encoder().encode(constants.bos)\n",
    "\n",
    "models = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL BERT\n",
    "config = {'model_name':'cl_bert',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_cl_bert_1, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_bert',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_cl_bert_2, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "models.extend([random_cl_bert_1, random_cl_bert_2])\n",
    "labels.extend(['random_cl_bert_1', 'random_cl_bert_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL BERT Shared\n",
    "config = {'model_name':'cl_bert_shared',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_cl_bert_shared_1, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_bert_shared',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_cl_bert_shared_2, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "\n",
    "models.extend([random_cl_bert_shared_1, random_cl_bert_shared_2])\n",
    "labels.extend(['random_cl_bert_shared_1', 'random_cl_bert_shared_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL LSTM\n",
    "config = {'model_name':'cl_lstm',\n",
    "        'model_config':'small_lstm_v4',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_cl_lstm_1, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_lstm',\n",
    "        'model_config':'small_lstm_v4',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_cl_lstm_2, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "\n",
    "models.extend([random_cl_lstm_1, random_cl_lstm_2])\n",
    "labels.extend(['random_cl_lstm_1', 'random_cl_lstm_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL LSTM BIG\n",
    "config = {'model_name':'cl_lstm',\n",
    "        'model_config':'lstm_drop31_v2',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_big_cl_lstm_1, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_lstm',\n",
    "        'model_config':'lstm_drop31_v2',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task1, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_big_cl_lstm_2, ckpt = get_model(config, task1, hparams, cl_token)\n",
    "\n",
    "\n",
    "models.extend([random_big_cl_lstm_1, random_big_cl_lstm_2])\n",
    "labels.extend(['random_big_cl_lstm_1', 'random_big_cl_lstm_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM GPT2\n",
    "config = {'model_name':'lm_gpt2',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_lm_gpt2_1, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_bert',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_lm_gpt2_2, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "models.extend([random_lm_gpt2_1, random_lm_gpt2_2])\n",
    "labels.extend(['random_lm_gpt2_1', 'random_lm_gpt2_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM GPT2 Shared\n",
    "\n",
    "config = {'model_name':'lm_gpt2_shared',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_lm_gpt2_shared_1, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'lm_gpt2_shared',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_lm_gpt2_shared_2, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "\n",
    "models.extend([random_lm_gpt2_shared_1, random_lm_gpt2_shared_2])\n",
    "labels.extend(['random_lm_gpt2_shared_1', 'random_lm_gpt2_shared_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM LSTM\n",
    "config = {'model_name':'lm_lstm_shared_emb',\n",
    "        'model_config':'small_lstm_v4',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_lm_lstm_1, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_lstm',\n",
    "        'model_config':'small_lstm_v4',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_lm_lstm_2, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "\n",
    "models.extend([random_lm_lstm_1, random_lm_lstm_2])\n",
    "labels.extend(['random_lm_lstm_1', 'random_lm_lstm_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big LM LSTM\n",
    "config = {'model_name':'lm_lstm',\n",
    "        'model_config':'lstm_drop31_v2',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random1',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_big_lm_lstm_1, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "config = {'model_name':'cl_lstm',\n",
    "        'model_config':'lstm_drop31_v2',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'random2',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task2, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "random_big_lm_lstm_2, ckpt = get_model(config, task2, hparams, cl_token)\n",
    "\n",
    "\n",
    "models.extend([random_big_lm_lstm_1, random_big_lm_lstm_2])\n",
    "labels.extend(['random_big_lm_lstm_1', 'random_big_lm_lstm_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_outputs(model, x):\n",
    "  outputs = model.detailed_call(x, training=tf.convert_to_tensor(True))\n",
    "  logits, reps = outputs[0], outputs[model.rep_index]\n",
    "  if model.rep_layer is not None:\n",
    "    reps = reps[model.rep_layer]\n",
    "\n",
    "  return reps, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task2\n",
    "\n",
    "reploss_dic = {}\n",
    "for l1 in labels:\n",
    "    reploss_dic[l1] = {}\n",
    "    for l2 in labels:\n",
    "        reploss_dic[l1][l2] = []\n",
    "        \n",
    "num_batches = 0\n",
    "for x, y in task.valid_dataset:\n",
    "    reps = []\n",
    "    for m in models:\n",
    "        outputs = get_outputs(m, x)\n",
    "        reps.append(outputs[0])\n",
    "    for i in np.arange(len(labels)):\n",
    "        for j in np.arange(i, len(labels)):\n",
    "            reploss = rep_loss(reps1=reps[i], reps2=reps[j],\n",
    "                                 padding_symbol=tf.constant(task.input_padding_symbol, dtype=tf.int64),\n",
    "                                 inputs=x)\n",
    "            reploss_dic[labels[i]][labels[j]].append(reploss)\n",
    "            if i != j:\n",
    "                reploss_dic[labels[j]][labels[i]].append(reploss)\n",
    "    num_batches += 1\n",
    "\n",
    "    if num_batches > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1 in reploss_dic.keys():\n",
    "    for l2 in  reploss_dic[l1].keys():\n",
    "        print(l1, l2, len(reploss_dic[l1][l2]), np.mean(reploss_dic[l1][l2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

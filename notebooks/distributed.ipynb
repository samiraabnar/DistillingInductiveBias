{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
    "# We are doing this because the first layer in our model is a convolutional\n",
    "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
    "# batch_size dimension will be added later on.\n",
    "train_images = train_images[..., None]\n",
    "test_images = test_images[..., None]\n",
    "\n",
    "# Getting the images in [0, 1] range.\n",
    "train_images = train_images / np.float32(255)\n",
    "test_images = test_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_images)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 16\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE) \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE) \n",
    "\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
    "  # global batch size.\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True,\n",
    "      reduction=tf.keras.losses.Reduction.NONE)\n",
    "  def compute_loss(labels, predictions):\n",
    "    per_example_loss = loss_object(labels, predictions)\n",
    "    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='train_accuracy')\n",
    "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer must be created under `strategy.scope`.\n",
    "with strategy.scope():\n",
    "  model = create_model()\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      predictions = model(images, training=True)\n",
    "      loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss, predictions \n",
    "\n",
    "  def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1, Loss: 0.4464421570301056, Accuracy: 83.72000122070312, Test Loss: 0.3529491126537323, Test Accuracy: 87.55000305175781\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  # `run` replicates the provided computation and runs it\n",
    "  # with the distributed input.\n",
    "  @tf.function\n",
    "  def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses, per_replica_predictions = strategy.experimental_run_v2(train_step, args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                           axis=None), per_replica_predictions\n",
    " \n",
    "  @tf.function\n",
    "  def distributed_test_step(dataset_inputs):\n",
    "    return strategy.experimental_run_v2(test_step, args=(dataset_inputs,))\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    # TRAIN LOOP\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for x in train_dist_dataset:\n",
    "      loss, per_replica_predictions = distributed_train_step(x)\n",
    "      total_loss += loss\n",
    "      num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    # TEST LOOP\n",
    "    for x in test_dist_dataset:\n",
    "      distributed_test_step(x)\n",
    "\n",
    "\n",
    "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
    "                \"Test Accuracy: {}\")\n",
    "    print (template.format(epoch+1, train_loss,\n",
    "                           train_accuracy.result()*100, test_loss.result(),\n",
    "                           test_accuracy.result()*100))\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 10), dtype=float32, numpy=\n",
       "array([[  6.7312727 ,  -1.6091244 ,  -0.06497218,   0.8819937 ,\n",
       "         -2.9817572 ,  -4.9757714 ,   3.5792334 ,  -6.100062  ,\n",
       "         -1.09286   ,  -4.037592  ],\n",
       "       [ -1.2379279 ,  -3.938323  ,   6.472806  ,  -0.41371906,\n",
       "          5.9494867 ,  -6.394777  ,   1.2372278 ,  -8.913586  ,\n",
       "         -0.04357997,  -8.745478  ],\n",
       "       [ -6.4974494 , -14.12088   ,  -8.516809  ,  -3.5889118 ,\n",
       "         -7.969909  ,   5.0643444 ,  -6.79579   ,  10.441473  ,\n",
       "          0.1867151 ,   5.8311043 ],\n",
       "       [ -1.9673445 ,   0.48762375,  -3.1698112 ,   5.6242065 ,\n",
       "         -2.4876537 ,  -0.35391805,  -2.1810849 ,  -3.108228  ,\n",
       "         -1.7661748 ,  -2.3138983 ],\n",
       "       [ -5.747141  ,  -9.4875965 ,  -7.071219  ,  -6.3860908 ,\n",
       "         -8.004895  ,   2.742964  ,  -3.3828218 ,   4.1335053 ,\n",
       "          0.22667333,  12.409351  ],\n",
       "       [ -7.5411143 , -10.38132   ,  -8.168939  ,  -7.113113  ,\n",
       "         -6.584156  ,   4.0573215 ,  -2.9296384 ,   5.668868  ,\n",
       "         -0.16586724,  14.190853  ],\n",
       "       [  3.3074882 ,  -2.6238706 ,  -1.3241086 ,   5.82756   ,\n",
       "         -4.769764  ,  -2.6794598 ,   3.437224  ,  -6.4528685 ,\n",
       "         -1.0545766 ,  -5.270408  ],\n",
       "       [ -2.872235  ,  -8.064886  ,  -3.6066344 ,  -4.6090965 ,\n",
       "         -5.0010424 ,  12.737818  ,  -2.4813993 ,  -1.1450651 ,\n",
       "         -1.5701623 ,  -3.1957572 ],\n",
       "       [  4.4409885 ,  -2.4155529 ,  -0.07475318,   2.2198133 ,\n",
       "         -2.3497858 ,  -2.6166878 ,   2.505162  ,  -4.894714  ,\n",
       "         -0.39167288,  -6.607423  ],\n",
       "       [  9.4410925 ,  -3.5608933 ,   0.0727496 ,   3.9059103 ,\n",
       "         -3.6906908 ,  -7.6648736 ,   5.370559  ,  -9.416109  ,\n",
       "         -1.0031319 ,  -7.558325  ],\n",
       "       [ -2.749652  ,  -9.167786  ,  -4.8052583 ,  -5.2842345 ,\n",
       "         -5.541092  ,  12.620133  ,  -1.4058038 ,  -1.2136921 ,\n",
       "         -1.0801239 ,  -2.0794582 ],\n",
       "       [ -3.2268429 ,  -8.748761  ,  -5.4756455 ,  -3.472737  ,\n",
       "         -5.2711678 ,   2.3782656 ,  -3.2815478 ,   7.175905  ,\n",
       "         -0.49916425,   4.6867905 ],\n",
       "       [  6.2821493 ,  -1.8005059 ,  -0.7015505 ,   4.1365466 ,\n",
       "         -4.1994486 ,  -5.743524  ,   6.3902073 ,  -7.254671  ,\n",
       "          0.0620586 ,  -6.4680843 ],\n",
       "       [  0.3864764 ,   9.192798  ,  -1.2056227 ,  -1.1384135 ,\n",
       "          1.2326269 ,  -2.1275768 ,  -0.5804746 ,  -5.088784  ,\n",
       "         -0.574411  ,  -5.143483  ],\n",
       "       [ -7.0932064 ,  -8.825193  ,  -8.816918  ,  -7.335091  ,\n",
       "         -6.3194246 ,   5.3170567 ,  -2.668298  ,   3.7308881 ,\n",
       "          0.82179433,  13.323898  ],\n",
       "       [ -0.28176823,  -1.3322803 ,   2.6351705 ,   0.53263813,\n",
       "          1.7730583 ,  -2.7836955 ,   1.2833139 ,  -4.1239376 ,\n",
       "         -0.25232002,  -4.638473  ],\n",
       "       [  6.10647   ,  -2.1914966 ,   0.11133467,  -0.07964634,\n",
       "         -2.2790403 ,  -5.1385627 ,   2.872432  ,  -4.578931  ,\n",
       "         -1.0515924 ,  -2.8849614 ],\n",
       "       [ -0.6271375 ,  -3.468242  ,   3.2094939 ,  -1.452149  ,\n",
       "          4.71961   ,  -5.6695814 ,   1.3216327 ,  -6.2648373 ,\n",
       "          1.2007374 ,  -6.125182  ],\n",
       "       [ -3.2437243 ,  -2.5373387 ,   2.4539301 ,  -0.87305975,\n",
       "          9.48227   ,  -5.792283  ,   1.0635071 ,  -9.356794  ,\n",
       "          0.9472223 ,  -9.092085  ],\n",
       "       [ -3.3500311 ,  -9.823034  ,  -4.9004664 ,  -4.5797176 ,\n",
       "         -4.9488506 ,  10.783087  ,  -5.2746387 ,   4.122162  ,\n",
       "          1.54847   ,  -4.177849  ],\n",
       "       [ -6.507205  ,  -7.8805833 ,  -8.392573  ,  -4.9644346 ,\n",
       "         -4.9497433 ,   4.6218762 ,  -3.796464  ,   8.612081  ,\n",
       "          0.40750393,   6.862643  ],\n",
       "       [  3.2426817 ,  -3.0447986 ,   5.8337283 ,  -2.2896016 ,\n",
       "          0.7584183 ,  -5.3164744 ,   3.028422  ,  -8.854866  ,\n",
       "         -2.3249104 ,  -6.7787414 ],\n",
       "       [  2.1355767 ,  -0.47601384,   0.04046081,   7.858693  ,\n",
       "          1.3540643 ,  -5.0012374 ,   2.3154168 ,  -6.6943917 ,\n",
       "         -0.76814705,  -8.370845  ],\n",
       "       [ -6.400888  ,  -8.054192  ,  -7.24871   ,  -6.978658  ,\n",
       "         -7.6201153 ,  14.648695  ,  -3.2279603 ,  -0.17487529,\n",
       "         -4.6682076 ,   5.959983  ],\n",
       "       [ -3.4879277 , -10.611883  ,  -5.701678  ,  -3.645696  ,\n",
       "         -6.099657  ,   5.82515   ,  -4.8343806 ,   7.932036  ,\n",
       "          1.046711  ,   0.4590068 ],\n",
       "       [ -1.8948932 , -13.6507435 ,  -5.7579    ,  -5.47716   ,\n",
       "         -3.0729976 ,  13.919884  ,  -3.2268908 ,  -2.408829  ,\n",
       "          3.289573  ,  -9.142628  ],\n",
       "       [ -5.2937603 ,  -8.81885   ,  -7.711818  ,  -4.496671  ,\n",
       "         -4.8819895 ,   7.9073234 ,  -1.2588917 ,   3.666364  ,\n",
       "         -2.3683648 ,   7.3831415 ],\n",
       "       [ -7.226701  ,  -8.405785  ,  -6.8097043 ,  -4.145766  ,\n",
       "         -6.5570946 ,   5.786214  ,  -2.4379978 ,   1.9852742 ,\n",
       "         -1.4229182 ,  12.704212  ],\n",
       "       [ -4.1923065 ,  -9.437679  ,  -7.016586  ,  -1.898454  ,\n",
       "         -5.1690674 ,   5.1130166 ,  -3.6511045 ,   6.280446  ,\n",
       "         -0.8273217 ,   3.547458  ],\n",
       "       [  2.0977445 ,  10.852825  ,   0.4179246 ,  -1.6658053 ,\n",
       "          0.6880796 ,  -0.6221219 ,  -3.3139572 ,  -7.688884  ,\n",
       "         -0.88656336,  -8.413544  ],\n",
       "       [ -0.19073153,  -5.88279   ,   5.9719524 ,   1.7465059 ,\n",
       "          4.766477  ,  -6.089376  ,   3.5027378 , -10.5075865 ,\n",
       "         -1.9728262 , -11.336266  ],\n",
       "       [ -1.7670176 , -10.767102  ,  -4.980474  ,  -3.319928  ,\n",
       "         -3.1171951 ,  11.165321  ,  -3.6705606 ,   0.8286925 ,\n",
       "          1.3868703 ,  -6.034787  ]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(strategy.unwrap(per_replica_predictions), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy.unwrap(per_replica_predictions)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

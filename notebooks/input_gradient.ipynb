{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from util import constants\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "from util.models import MODELS\n",
    "from util.tasks import TASKS\n",
    "from notebook_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[4]\n",
      "[1]\n",
      "[2]\n",
      "[23, 14, 280]\n",
      "[8055]\n"
     ]
    }
   ],
   "source": [
    "task = 'sst2'\n",
    "\n",
    "chkpt_dir='../tf_ckpts'\n",
    "task = TASKS[task](get_task_params(), data_dir='../data')\n",
    "cl_token = task.sentence_encoder().encode(constants.bos)\n",
    "print(task.sentence_encoder().encode(constants.bos))\n",
    "print(task.sentence_encoder().encode(constants.eos))\n",
    "print(task.sentence_encoder().encode(constants.pad))\n",
    "print(task.sentence_encoder().encode(constants.unk))\n",
    "print(task.sentence_encoder().encode('this is good'))\n",
    "\n",
    "print(task.sentence_encoder().encode(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: small_gpt_v9\n",
      "{'embedding_dim': 128, 'resid_pdrop': 0.4, 'embd_pdrop': 0.2, 'attn_pdrop': 0.6, 'initializer_range': 0.05}\n",
      "No checkpoint found ../tf_ckpts/sst2/cl_bert_h-128_d-6_rdrop-0.4_adrop-0.6_indrop-0.2_small_gpt_v9_0.001_test\n"
     ]
    }
   ],
   "source": [
    "config = {'model_name':'cl_bert',\n",
    "        'model_config':'small_gpt_v9',\n",
    "        'learning_rate':0.001,\n",
    "        'exp_name':'test',\n",
    "        'chkpt_dir': '../tf_ckpts'\n",
    "}\n",
    "hparams=get_model_params(task, config['model_name'], config['model_config'])\n",
    "hparams.output_attentions = True\n",
    "hparams.output_embeddings = True\n",
    "\n",
    "cl_bert, ckpt = get_model(config, task, hparams, cl_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x1,y1 in task.valid_dataset:\n",
    "    y = cl_bert(x1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = cl_bert(x1)\n",
    "\n",
    "grads = tape.gradient(y, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings, input_shape, padding_mask, past = cl_bert.get_input_embeddings(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 57) (64, 58, 128)\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape, input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 58, 128)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(input_embeddings)\n",
    "    outputs = cl_bert.call_with_embeddings(input_embeddings, input_shape, padding_mask, past)\n",
    "    logits = outputs[0]\n",
    "    \n",
    "grads = tape.gradient(logits, input_embeddings)\n",
    "print(grads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

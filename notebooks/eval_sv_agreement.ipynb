{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tasks.tasks import SvAgreementLM, WordSvAgreementLM, WordSvAgreementVP\n",
    "from tf2_models.lm_transformer import LmGPT2, ClassifierGPT2\n",
    "from util.config_util import get_model_params, get_task_params, get_train_params\n",
    "from tf2_models.lm_lstm import LmLSTM, LmLSTMSharedEmb, ClassifierLSTM\n",
    "from tf2_models.trainer import Trainer\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from util import constants\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tf2_models.metrics import *\n",
    "\n",
    "MODELS = {\"lm_lstm\": LmLSTM,\n",
    "          \"lm_gpt2\": LmGPT2,\n",
    "          \"lm_lstm_shared_emb\": LmLSTMSharedEmb,\n",
    "          'cl_gpt2': ClassifierGPT2,\n",
    "          'cl_lstm': ClassifierLSTM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab len:  10034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"../logs\"\n",
    "chkpt_dir = \"../tf_ckpts\"\n",
    "exp_name = \"nol2_batchsumloss\"\n",
    "\n",
    "task = WordSvAgreementLM(task_params=get_task_params(),data_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: lstm_drop30_v2\n",
      "{'hidden_dim': 512, 'embedding_dim': 512, 'depth': 2, 'hidden_dropout_rate': 0.3, 'input_dropout_rate': 0.0, 'initializer_range': 0.1}\n",
      "model_params:  {'embedding_dim': 512, 'hidden_dim': 512, 'input_dim': 10036, 'output_dim': 10036, 'depth': 2, 'hidden_dropout_rate': 0.3, 'input_dropout_rate': 0.0, 'initializer_range': 0.1}\n",
      "model config: lstm_drop30_v2\n",
      "{'hidden_dim': 512, 'embedding_dim': 512, 'depth': 2, 'hidden_dropout_rate': 0.3, 'input_dropout_rate': 0.0, 'initializer_range': 0.1}\n",
      "../logs/word_sv_agreement_lm/lm_lstm_shared_emb_em-512_h-512_d-2_hdrop-0.3_indrop-0.0_lstm_drop30_v2_0.001_nol2_batchsumloss\n",
      "Model: \"lm_lstm_shared_emb\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (SharedEmbeddings) multiple                  5138432   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  262656    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  2099200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  2099200   \n",
      "=================================================================\n",
      "Total params: 9,601,536\n",
      "Trainable params: 9,601,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Variable 'embedding/weight:0' shape=(10036, 512) dtype=float32, numpy=\n",
      "array([[ 0.01588651,  0.11146805, -0.157184  , ..., -0.09914309,\n",
      "        -0.00193671, -0.05611856],\n",
      "       [ 0.04604439,  0.15325962,  0.10854249, ..., -0.17056903,\n",
      "         0.0536123 ,  0.09335702],\n",
      "       [ 0.00206014,  0.00116901, -0.15813515, ..., -0.066883  ,\n",
      "        -0.1071504 , -0.04769658],\n",
      "       ...,\n",
      "       [ 0.01922283,  0.00672257, -0.06964251, ...,  0.16332573,\n",
      "         0.08194473,  0.02468162],\n",
      "       [ 0.04687477,  0.09288102, -0.10296684, ...,  0.13407065,\n",
      "        -0.00130703,  0.05486666],\n",
      "       [ 0.07636828,  0.01962619, -0.09612881, ...,  0.08351997,\n",
      "        -0.12270772,  0.05014619]], dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
      "array([[-0.15284315, -0.04440648,  0.02221038, ...,  0.0311838 ,\n",
      "         0.11940809, -0.01670442],\n",
      "       [ 0.12864308, -0.0160995 , -0.14380908, ...,  0.08928549,\n",
      "         0.0024622 ,  0.01638907],\n",
      "       [ 0.06848537,  0.02159767, -0.07899301, ...,  0.03284946,\n",
      "        -0.03321096, -0.1786621 ],\n",
      "       ...,\n",
      "       [ 0.03315214,  0.02864412,  0.05095239, ...,  0.05367268,\n",
      "         0.06128348, -0.02665311],\n",
      "       [-0.01867994,  0.03621428, -0.05494998, ...,  0.11125185,\n",
      "         0.05120174, -0.06879556],\n",
      "       [ 0.00343858,  0.08913574,  0.15403853, ..., -0.03189832,\n",
      "         0.07610371, -0.12451652]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'lstm/kernel:0' shape=(512, 2048) dtype=float32, numpy=\n",
      "array([[ 0.0794931 ,  0.12690865,  0.00880121, ..., -0.13687596,\n",
      "        -0.06562048,  0.01597646],\n",
      "       [ 0.04011902,  0.10994794,  0.02050555, ...,  0.03856206,\n",
      "        -0.01957343,  0.03528098],\n",
      "       [ 0.0733557 ,  0.00604311,  0.0277449 , ..., -0.08437978,\n",
      "        -0.02988966, -0.08505595],\n",
      "       ...,\n",
      "       [-0.09482623,  0.08729856, -0.07620084, ...,  0.06856382,\n",
      "         0.09040975, -0.04362206],\n",
      "       [-0.02300929,  0.01526631, -0.00402116, ..., -0.0077435 ,\n",
      "         0.11747225, -0.06389175],\n",
      "       [-0.17049621, -0.04362803, -0.07544395, ...,  0.06336246,\n",
      "         0.02546048,  0.05006517]], dtype=float32)>, <tf.Variable 'lstm/recurrent_kernel:0' shape=(512, 2048) dtype=float32, numpy=\n",
      "array([[ 0.05011066,  0.09023347, -0.12436237, ...,  0.06209856,\n",
      "         0.14809267, -0.17794581],\n",
      "       [ 0.12164658, -0.16874212,  0.16467977, ...,  0.18035533,\n",
      "        -0.05508849, -0.09067973],\n",
      "       [ 0.02783225, -0.11293586,  0.0702422 , ...,  0.0317557 ,\n",
      "        -0.03668296, -0.03587426],\n",
      "       ...,\n",
      "       [ 0.09270724, -0.00344994,  0.08456329, ..., -0.07112817,\n",
      "         0.05659574, -0.05974999],\n",
      "       [-0.00025486,  0.03482704,  0.10795923, ...,  0.1474037 ,\n",
      "        -0.01866474,  0.06749048],\n",
      "       [ 0.06908555, -0.1427552 ,  0.0609089 , ...,  0.0168179 ,\n",
      "        -0.05662942, -0.00833906]], dtype=float32)>, <tf.Variable 'lstm/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_1/kernel:0' shape=(512, 2048) dtype=float32, numpy=\n",
      "array([[ 0.10701537,  0.17466854,  0.19064425, ...,  0.09612416,\n",
      "         0.04649169, -0.11893719],\n",
      "       [ 0.03952954, -0.00276243,  0.00749045, ..., -0.10251439,\n",
      "         0.01264743,  0.09466738],\n",
      "       [ 0.15336832,  0.10675539, -0.01601536, ..., -0.09031921,\n",
      "        -0.13124555, -0.13335635],\n",
      "       ...,\n",
      "       [-0.1444476 ,  0.11335637, -0.02734504, ..., -0.10284318,\n",
      "        -0.11529464,  0.0853586 ],\n",
      "       [-0.01350933, -0.01785004,  0.0173226 , ..., -0.06714675,\n",
      "         0.11595793, -0.07475702],\n",
      "       [ 0.04000658, -0.07148715, -0.02585092, ...,  0.05574819,\n",
      "         0.0308959 ,  0.01347302]], dtype=float32)>, <tf.Variable 'lstm_1/recurrent_kernel:0' shape=(512, 2048) dtype=float32, numpy=\n",
      "array([[ 0.03858569, -0.04791191,  0.15733352, ...,  0.07966432,\n",
      "         0.0565785 ,  0.03698669],\n",
      "       [-0.06685115, -0.02230516, -0.04769666, ..., -0.03960849,\n",
      "        -0.07248998,  0.01715961],\n",
      "       [ 0.02935541,  0.09669932,  0.08200186, ..., -0.10995471,\n",
      "         0.08333136,  0.08055697],\n",
      "       ...,\n",
      "       [ 0.10072706, -0.04574476, -0.11556494, ..., -0.19074516,\n",
      "        -0.0989264 , -0.07463676],\n",
      "       [ 0.02106751, -0.0779848 , -0.05953107, ...,  0.05935123,\n",
      "        -0.07803003, -0.17789532],\n",
      "       [ 0.10652252,  0.08417543,  0.15009847, ...,  0.12353957,\n",
      "        -0.18432152, -0.10714503]], dtype=float32)>, <tf.Variable 'lstm_1/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_init_0:0' shape=(1, 512) dtype=float32, numpy=\n",
      "array([[-0.08543178, -0.10307042, -0.18028666,  0.0975569 , -0.09128167,\n",
      "        -0.16986473,  0.02806783,  0.07055821, -0.02246176,  0.06092975,\n",
      "        -0.03295268, -0.02408834, -0.03738572,  0.02057983, -0.06733521,\n",
      "         0.01246191,  0.02347224,  0.03921387, -0.12840544, -0.07213398,\n",
      "        -0.0776227 , -0.1424974 , -0.02176648, -0.14339128,  0.08300646,\n",
      "        -0.07420646, -0.07481774,  0.03919119, -0.01414741, -0.01122438,\n",
      "        -0.04761065, -0.13189349, -0.02302447, -0.08812937,  0.04073214,\n",
      "        -0.0187732 , -0.0656622 ,  0.06508616,  0.12902991,  0.01970592,\n",
      "         0.1220445 , -0.10133393,  0.05306255, -0.00238772, -0.12408616,\n",
      "        -0.02710647,  0.02213064, -0.02243703,  0.03129114, -0.06091996,\n",
      "         0.09177309, -0.14797346, -0.00856232, -0.03660173,  0.09992939,\n",
      "        -0.08146801, -0.0452471 ,  0.15086196, -0.08800207, -0.0360757 ,\n",
      "         0.17090917,  0.07442766,  0.08911957,  0.04319598, -0.00953892,\n",
      "         0.01637438, -0.00723504,  0.01902179,  0.10199256,  0.01306498,\n",
      "         0.02134766, -0.03026168,  0.10464042, -0.09522886, -0.06835587,\n",
      "         0.1309124 ,  0.10341797, -0.11613863,  0.04112535, -0.01460865,\n",
      "         0.15798129,  0.01406063,  0.0452505 ,  0.0496031 , -0.02405085,\n",
      "         0.0155082 ,  0.162169  , -0.0510981 , -0.11151695,  0.05398703,\n",
      "        -0.1003707 , -0.15564275,  0.04929955,  0.10781898,  0.02896297,\n",
      "        -0.0772576 , -0.05674476, -0.05323341,  0.03946803,  0.01389778,\n",
      "        -0.04689778, -0.06514928, -0.16774875,  0.0229814 ,  0.01222953,\n",
      "        -0.02392058,  0.0036836 ,  0.05041754,  0.12261724,  0.16590425,\n",
      "        -0.14384699, -0.02110254,  0.00605237,  0.13293068, -0.07344072,\n",
      "        -0.04349114,  0.1399223 ,  0.03283529, -0.15699688,  0.02146926,\n",
      "        -0.06480671,  0.02815852, -0.1248853 ,  0.06423428,  0.01845646,\n",
      "        -0.07594755,  0.1681149 ,  0.112656  , -0.0491407 , -0.10495233,\n",
      "        -0.13791214, -0.01832853,  0.00596626,  0.07795252, -0.00833339,\n",
      "        -0.03369603,  0.12300092, -0.05583822,  0.01295038,  0.02681255,\n",
      "         0.1758088 , -0.07405069,  0.0412638 ,  0.03051651, -0.15242042,\n",
      "         0.01168639,  0.11233985,  0.0078928 , -0.05455107, -0.145477  ,\n",
      "        -0.15902455,  0.08462618,  0.19403692,  0.08582918,  0.00668524,\n",
      "        -0.03157599,  0.14029044,  0.00930906, -0.02761733, -0.09440259,\n",
      "         0.07408388, -0.02678425, -0.12774216, -0.10835544,  0.00130297,\n",
      "         0.17976353, -0.04130234,  0.03415534, -0.07057904, -0.03321129,\n",
      "         0.05892704,  0.0589101 , -0.07666455, -0.05052705, -0.10752552,\n",
      "        -0.0484381 , -0.05766543, -0.1031893 , -0.1748918 , -0.01144113,\n",
      "        -0.10326552,  0.0028395 ,  0.03413766,  0.01986869,  0.04138031,\n",
      "         0.04632992, -0.09776434,  0.0439601 ,  0.00475609,  0.16418003,\n",
      "         0.15842792,  0.0949245 ,  0.0922883 , -0.03299267,  0.07480552,\n",
      "        -0.0703453 , -0.09431764, -0.14671925, -0.11502333, -0.01999714,\n",
      "         0.01916212, -0.03414239,  0.05481114,  0.01246782,  0.13789704,\n",
      "         0.01608649, -0.04249654, -0.10554325,  0.05347889, -0.14952454,\n",
      "        -0.02527084,  0.04953451,  0.01096345, -0.09246032,  0.06580717,\n",
      "         0.04937695,  0.16887312,  0.02400677,  0.08122575,  0.14590123,\n",
      "        -0.10550576,  0.0110395 ,  0.05437744, -0.06082159, -0.00210367,\n",
      "         0.09937312,  0.11938258,  0.0520196 , -0.17155494,  0.13671812,\n",
      "        -0.03002783,  0.10277474, -0.02359402, -0.00597131, -0.04073872,\n",
      "         0.0113169 , -0.14121813, -0.17236476,  0.04205209,  0.03034465,\n",
      "         0.11119962, -0.07022879, -0.01667387,  0.1496114 , -0.06352881,\n",
      "         0.0344161 ,  0.08829439, -0.00502635, -0.09244099, -0.16703074,\n",
      "         0.06138728, -0.03433099, -0.06764378, -0.14310977,  0.06677869,\n",
      "         0.17762576, -0.12879711,  0.03029346, -0.08726301,  0.00589344,\n",
      "        -0.00988404,  0.18129693,  0.09332441,  0.1264886 , -0.0783008 ,\n",
      "        -0.01192664, -0.09630118, -0.0019006 , -0.0549668 ,  0.01221138,\n",
      "         0.02246146, -0.05319457, -0.00752972, -0.06910953, -0.14539081,\n",
      "         0.06246299,  0.0817709 , -0.00446282,  0.16808991, -0.05389956,\n",
      "        -0.10856849,  0.00200583, -0.01580876, -0.00628758, -0.02913707,\n",
      "         0.1415462 , -0.05155748, -0.00837604, -0.00927662, -0.01983302,\n",
      "         0.165578  ,  0.09807634, -0.04114775, -0.04880303, -0.15503423,\n",
      "         0.11774649, -0.17358364,  0.05514873, -0.0938234 , -0.09272334,\n",
      "         0.1107921 ,  0.11165585, -0.05030393,  0.06422947,  0.08414673,\n",
      "         0.00911139, -0.02758831,  0.04542375,  0.05310142, -0.06804537,\n",
      "         0.10991464,  0.02577935,  0.01146326, -0.12954971,  0.04433521,\n",
      "         0.05459172, -0.07280641,  0.0358972 ,  0.06037894, -0.04080121,\n",
      "         0.05723473, -0.12940222, -0.17913894, -0.08698128, -0.11129072,\n",
      "        -0.06418835,  0.02033884, -0.04819343, -0.0117537 ,  0.07173865,\n",
      "        -0.00972386, -0.0195116 , -0.18853725,  0.06145804, -0.05870959,\n",
      "        -0.12520514, -0.08435144,  0.02134735,  0.02128793, -0.17056906,\n",
      "         0.03136235,  0.1029226 ,  0.03567733, -0.11416798,  0.08642689,\n",
      "         0.0224944 ,  0.04851903, -0.12907551,  0.05151364,  0.07927486,\n",
      "         0.16374354,  0.04556886, -0.09569653, -0.06853776, -0.0213624 ,\n",
      "        -0.13475738, -0.18832274, -0.10480118,  0.10676203,  0.00502281,\n",
      "        -0.16864464,  0.09022661, -0.00100093,  0.05100346, -0.07781871,\n",
      "         0.09912031,  0.13630375, -0.05590585,  0.09263789,  0.03318511,\n",
      "         0.02167627, -0.02967014, -0.04052375, -0.11513223,  0.04922236,\n",
      "        -0.0150917 , -0.10676499, -0.16075662,  0.10755301,  0.01552011,\n",
      "        -0.02960162,  0.00262961, -0.10356425, -0.041217  ,  0.05652247,\n",
      "         0.06806111, -0.08503606, -0.11056977,  0.08444786, -0.17105763,\n",
      "        -0.04374684, -0.01049018,  0.15489918, -0.07727119, -0.06671254,\n",
      "         0.07848258, -0.03806803, -0.19936441, -0.01671806, -0.03766332,\n",
      "        -0.02444978, -0.01879932, -0.00419206,  0.01149408, -0.01941896,\n",
      "        -0.01263405, -0.08885249, -0.07393827, -0.05476987, -0.07946222,\n",
      "        -0.02488296, -0.04927345,  0.145367  ,  0.01783911, -0.16617928,\n",
      "        -0.01793382, -0.02937554,  0.02719975, -0.07843585,  0.10336719,\n",
      "        -0.03706087,  0.03666802,  0.01529995, -0.0039503 , -0.12032785,\n",
      "        -0.13303745, -0.03278753,  0.10865023, -0.0174627 ,  0.14216946,\n",
      "        -0.14371234, -0.02912206, -0.05509762, -0.03263603,  0.04178045,\n",
      "        -0.0509658 , -0.11241262,  0.11329091, -0.08882301,  0.07657593,\n",
      "        -0.02961634,  0.01305902,  0.06422158, -0.0851829 , -0.08026772,\n",
      "         0.12341072,  0.13914104,  0.00020353, -0.01967585, -0.05581226,\n",
      "         0.0407112 , -0.03542091,  0.06164138, -0.00546492, -0.09280825,\n",
      "         0.04129417, -0.12135442,  0.07238238, -0.02177168, -0.03593127,\n",
      "        -0.1929786 , -0.1858542 ,  0.07272798, -0.0579399 ,  0.09752309,\n",
      "        -0.08572806,  0.03310674, -0.18472122, -0.0730077 ,  0.02787007,\n",
      "        -0.13299541,  0.0197991 ,  0.04805171,  0.09660935,  0.02163382,\n",
      "         0.1342968 , -0.12795855, -0.09443675, -0.08424608,  0.04916167,\n",
      "         0.13818167, -0.11480211,  0.14735946,  0.09297065,  0.12511571,\n",
      "         0.05598105,  0.04332539, -0.00762957, -0.02361139, -0.0265724 ,\n",
      "        -0.0198499 , -0.12906912, -0.10130381,  0.00813116,  0.08074256,\n",
      "         0.14146791,  0.0980901 ,  0.00207527,  0.02453573, -0.01397935,\n",
      "        -0.06900089, -0.1137399 , -0.02629092,  0.0376964 , -0.05111542,\n",
      "        -0.00714002,  0.07525506, -0.05431549, -0.00192037, -0.12399685,\n",
      "         0.03655933,  0.1485001 ]], dtype=float32)>, <tf.Variable 'lstm_init_0:0' shape=(1, 512) dtype=float32, numpy=\n",
      "array([[-0.03615829, -0.04350445, -0.06596661, -0.07125153, -0.0225824 ,\n",
      "         0.02004957,  0.09363579, -0.04409398,  0.06980301, -0.0804786 ,\n",
      "        -0.0385399 , -0.04419304, -0.09678694, -0.00631583,  0.140573  ,\n",
      "         0.0528365 ,  0.04923553,  0.18650454, -0.0686813 ,  0.15471666,\n",
      "        -0.13201314, -0.04037716,  0.06362419, -0.12191856, -0.18229292,\n",
      "         0.19020857, -0.05775338,  0.12149966,  0.04842071, -0.07351129,\n",
      "        -0.11028301,  0.08428919,  0.10636784, -0.0768479 ,  0.01768384,\n",
      "         0.08998853,  0.0125835 ,  0.08475672,  0.03015921,  0.03574803,\n",
      "        -0.11330581, -0.15195867,  0.05648862, -0.02479435,  0.07524358,\n",
      "        -0.02932015,  0.06275155, -0.03264132, -0.13238522, -0.04606543,\n",
      "         0.03946933,  0.10258346,  0.02256148,  0.03954445, -0.03027993,\n",
      "        -0.12198267,  0.13841377,  0.0110371 , -0.01433417,  0.01284698,\n",
      "        -0.01392228,  0.02032038, -0.13684995,  0.09139826,  0.0402813 ,\n",
      "        -0.16018821,  0.12962286,  0.02497871,  0.01901294, -0.07946431,\n",
      "         0.11262323, -0.08303533, -0.04345415, -0.03519939,  0.00481047,\n",
      "        -0.07728987, -0.16552489,  0.07158051,  0.06028423,  0.05751961,\n",
      "         0.14606841, -0.07581931,  0.05385565,  0.13219886, -0.04504928,\n",
      "         0.18379852, -0.00606166,  0.02584819,  0.06080554, -0.12034296,\n",
      "         0.11446831, -0.01853405, -0.10033306,  0.17595325,  0.00930692,\n",
      "        -0.03460069,  0.19143471,  0.06701653, -0.0907736 , -0.09421162,\n",
      "         0.03919106,  0.04124765, -0.12108222,  0.03924552,  0.08210526,\n",
      "        -0.01520314, -0.03319474, -0.01409605, -0.00906399,  0.15291858,\n",
      "         0.1330449 ,  0.11813644, -0.03595958, -0.02197807,  0.02673061,\n",
      "         0.07331372, -0.04426916, -0.01823489,  0.17531377,  0.07223379,\n",
      "         0.02854305,  0.1584478 ,  0.07958376,  0.09729959,  0.14385642,\n",
      "        -0.1305339 , -0.01854693,  0.01741076,  0.00905538, -0.05066217,\n",
      "        -0.0254806 , -0.00411206,  0.02785676, -0.00032564, -0.08394294,\n",
      "         0.06259935,  0.00601158,  0.08841289,  0.09291349, -0.00868594,\n",
      "         0.05800465, -0.10164012,  0.0443098 ,  0.11509601, -0.02780965,\n",
      "        -0.04312151,  0.05494724, -0.08449401, -0.02815544, -0.13834305,\n",
      "        -0.1057769 , -0.10830752, -0.05222247,  0.01560411,  0.06019137,\n",
      "        -0.1495918 ,  0.00854994, -0.05976905,  0.1572557 , -0.02868549,\n",
      "        -0.16977726,  0.16897522,  0.02635782,  0.11411794, -0.02941053,\n",
      "         0.18099199,  0.00984407,  0.10550918,  0.10150559, -0.09601324,\n",
      "        -0.0464686 ,  0.0751945 ,  0.06385662, -0.05749745,  0.0860322 ,\n",
      "         0.04810263,  0.00587927,  0.09870549,  0.13860975, -0.0659344 ,\n",
      "        -0.05485665, -0.03056883,  0.02766912,  0.19465026,  0.05234779,\n",
      "        -0.039413  , -0.00282134,  0.06504119, -0.03815861, -0.02679458,\n",
      "        -0.0131469 ,  0.13020448,  0.08894397,  0.14861357,  0.06332098,\n",
      "         0.13040583,  0.05666904, -0.02049127, -0.19051187,  0.03334112,\n",
      "         0.0523668 , -0.00479583, -0.03683906, -0.02443768,  0.04453946,\n",
      "         0.11349712,  0.0856858 ,  0.02582352, -0.07341396, -0.01857929,\n",
      "         0.07903496, -0.05764055, -0.1330193 , -0.06368597,  0.17350449,\n",
      "         0.00528492, -0.09691328, -0.08783139,  0.1750791 ,  0.05288026,\n",
      "        -0.07725523, -0.13799018, -0.07614086, -0.04898713, -0.00364486,\n",
      "         0.04544863, -0.0753752 , -0.02314598, -0.11143348,  0.0008563 ,\n",
      "        -0.05938798, -0.14416383,  0.15262823, -0.129649  ,  0.04140059,\n",
      "        -0.05170664, -0.01325835,  0.13936158,  0.17675346,  0.04399117,\n",
      "         0.09451361, -0.08409046,  0.01327119, -0.09767912, -0.0648987 ,\n",
      "         0.04848867, -0.07842792,  0.11107192,  0.04118238,  0.01650024,\n",
      "         0.14467315, -0.10154349,  0.00156266, -0.12049667, -0.00952728,\n",
      "        -0.00838451, -0.00530396, -0.17803778, -0.10749207, -0.03874301,\n",
      "        -0.06925442,  0.03382452, -0.19606782,  0.03662291, -0.09764802,\n",
      "         0.08616526, -0.03002151, -0.01555616,  0.10942632, -0.05757618,\n",
      "        -0.03959476, -0.04532623, -0.1831051 ,  0.02484383,  0.01731082,\n",
      "        -0.13565317,  0.14918096, -0.0352161 , -0.06658872,  0.00396937,\n",
      "         0.06734379,  0.15081   , -0.04157836, -0.04044818, -0.11912687,\n",
      "        -0.01606523,  0.04886254, -0.01429065,  0.1340584 , -0.04054295,\n",
      "        -0.03450671, -0.02720781,  0.05359454, -0.00477256,  0.10974158,\n",
      "        -0.11694697,  0.10581209, -0.01448669, -0.18424754,  0.08371203,\n",
      "         0.0699287 ,  0.00198685, -0.07596444, -0.11853063, -0.01899203,\n",
      "         0.0091739 , -0.09521358,  0.13700725, -0.04123115, -0.05479858,\n",
      "         0.14604978,  0.11981063,  0.03047406,  0.01650482,  0.04162624,\n",
      "         0.00033044,  0.1038778 , -0.0575564 ,  0.12836874,  0.05311441,\n",
      "        -0.06680616, -0.113445  , -0.13893902,  0.05853214,  0.19434665,\n",
      "         0.10134771, -0.08358338,  0.16507022, -0.05317009, -0.12960741,\n",
      "         0.06137116,  0.16649945, -0.10886661, -0.00454953,  0.01957324,\n",
      "         0.02038543,  0.02551869,  0.08535343,  0.00295696,  0.08410966,\n",
      "        -0.07185566,  0.00931422,  0.06116644,  0.13479687, -0.10136189,\n",
      "        -0.11068877,  0.11879293, -0.0911093 ,  0.02975812, -0.04863015,\n",
      "        -0.12743855,  0.06016487,  0.00796492,  0.05593401,  0.09061455,\n",
      "        -0.18002455, -0.0205154 , -0.06347207, -0.15382682,  0.01460109,\n",
      "         0.00077437,  0.0102349 ,  0.06928302,  0.13020037,  0.17159086,\n",
      "        -0.05044612, -0.10887831,  0.08978399,  0.12658983, -0.14253111,\n",
      "         0.04127107,  0.00420435, -0.03384272,  0.08089144, -0.05023052,\n",
      "         0.0192272 , -0.02775279,  0.1630748 , -0.10423267,  0.04128217,\n",
      "         0.07816149, -0.09475898,  0.04736559, -0.0110623 ,  0.01411725,\n",
      "         0.0330747 , -0.10159712,  0.11710554,  0.03504656,  0.15719758,\n",
      "        -0.0581062 ,  0.07611778, -0.03585641,  0.08787488,  0.05468992,\n",
      "         0.05430155, -0.12952088, -0.00541199, -0.19035965, -0.07231491,\n",
      "        -0.13081817, -0.06271972, -0.04124587,  0.07854574, -0.12491434,\n",
      "         0.02635641, -0.10906661,  0.08540573,  0.16232973,  0.19940104,\n",
      "        -0.04021746, -0.10952681, -0.01343197, -0.00441728, -0.02445351,\n",
      "        -0.0172713 ,  0.06356432, -0.10620161, -0.0263191 , -0.04939264,\n",
      "        -0.02747803, -0.0498649 ,  0.13288362,  0.06174683,  0.01362512,\n",
      "        -0.18098228, -0.02567255,  0.05650788, -0.12321532,  0.04705552,\n",
      "        -0.03565494, -0.12920058, -0.12582324, -0.16467172,  0.17079549,\n",
      "         0.00802071,  0.17843914, -0.05058737,  0.01979798, -0.08875633,\n",
      "        -0.00199392, -0.10797782, -0.04358779, -0.05272273,  0.00423214,\n",
      "        -0.19130199, -0.02549235,  0.02660714,  0.02722316,  0.04227861,\n",
      "         0.13317811, -0.02447188,  0.02909094,  0.13660263, -0.03736805,\n",
      "        -0.02356353, -0.00946678,  0.16539226, -0.08185332, -0.0112391 ,\n",
      "         0.07623606,  0.16133234,  0.04345952, -0.04059131,  0.08911043,\n",
      "        -0.1303147 ,  0.1417698 ,  0.05263544, -0.00454542,  0.02843548,\n",
      "         0.04166829,  0.00666846,  0.01668145,  0.01453441, -0.06219741,\n",
      "        -0.06439921, -0.09131113, -0.11429834,  0.18609683,  0.09812114,\n",
      "         0.11426158, -0.10711211,  0.0269594 , -0.01398782, -0.08854672,\n",
      "         0.00029256,  0.03622017,  0.08455523,  0.01722163,  0.15739618,\n",
      "         0.16526288, -0.12072654, -0.03918849, -0.02274078,  0.03657388,\n",
      "         0.15038358, -0.05973988,  0.10766333,  0.09279492,  0.10791948,\n",
      "        -0.06246308, -0.04316009, -0.02572919,  0.10691627, -0.04837421,\n",
      "        -0.08428939, -0.0953346 ,  0.07232564, -0.13104507, -0.14676619,\n",
      "         0.17154229,  0.01315688]], dtype=float32)>, <tf.Variable 'lstm_init_1:0' shape=(1, 512) dtype=float32, numpy=\n",
      "array([[-3.90495099e-02,  1.17913857e-01, -1.36712834e-03,\n",
      "        -6.49479553e-02,  1.49599493e-01,  1.44816846e-01,\n",
      "         1.09940149e-01,  7.54364952e-02, -1.26631141e-01,\n",
      "        -1.49652943e-01,  3.88814993e-02, -9.66582373e-02,\n",
      "        -7.50123411e-02,  2.13042628e-02,  1.30946562e-01,\n",
      "        -1.06683433e-01, -1.84497222e-01,  9.66016352e-02,\n",
      "        -7.24283531e-02,  1.16850130e-01,  1.33330792e-01,\n",
      "         5.86420260e-02, -5.42767346e-02,  3.92660946e-02,\n",
      "        -1.91298336e-01, -5.41225187e-02, -1.78470895e-01,\n",
      "         1.44859171e-02, -5.87003939e-02,  3.73205394e-02,\n",
      "        -4.32824269e-02,  1.10010719e-02, -4.97136228e-02,\n",
      "         4.91092056e-02,  8.68934244e-02,  6.34476542e-02,\n",
      "         1.51883826e-01, -4.94213216e-02, -6.21322393e-02,\n",
      "         4.73404489e-02, -6.97804093e-02, -6.86250180e-02,\n",
      "         1.49274126e-01, -1.19713761e-01, -3.94272013e-03,\n",
      "         1.16438232e-01,  5.19297309e-02,  7.69186839e-02,\n",
      "         2.33018398e-02,  3.79314087e-02,  1.16606941e-03,\n",
      "         1.73049979e-02, -5.79014905e-02, -6.73593134e-02,\n",
      "         1.74399406e-01, -1.08540663e-03,  1.79532111e-01,\n",
      "        -2.73781101e-04, -1.94948137e-01, -4.09663729e-02,\n",
      "         4.53841574e-02, -1.24006895e-02, -8.16324204e-02,\n",
      "         6.44426346e-02,  9.42460671e-02, -7.05284923e-02,\n",
      "        -9.23706517e-02,  5.62176295e-02, -1.19034484e-01,\n",
      "        -3.71613470e-03,  4.30298224e-02,  4.10346352e-02,\n",
      "         3.79091725e-02, -4.57569994e-02,  1.20953299e-01,\n",
      "         1.31998276e-02, -1.75254587e-02, -3.98205817e-02,\n",
      "        -2.55654636e-03,  2.34738644e-03,  9.94607061e-03,\n",
      "         1.43912584e-01, -1.12507679e-01, -1.03007250e-01,\n",
      "        -2.96606924e-02, -5.56875281e-02,  7.98673183e-02,\n",
      "         9.46356356e-02,  9.91835594e-02, -4.86609302e-02,\n",
      "        -3.59873809e-02,  3.01399231e-02, -3.35935950e-02,\n",
      "        -1.47904537e-03,  1.00594731e-02,  1.90933913e-01,\n",
      "        -7.87982568e-02, -7.97803793e-03,  1.15442194e-01,\n",
      "         1.99998781e-01, -6.78703934e-02, -6.82275966e-02,\n",
      "        -8.75929669e-02,  7.19577968e-02,  1.12894930e-01,\n",
      "         3.37163135e-02, -1.09997988e-01, -5.57970256e-03,\n",
      "         7.18896911e-02, -1.82658434e-01, -1.05855979e-01,\n",
      "        -7.67185092e-02, -6.98502883e-02, -1.90734133e-01,\n",
      "         1.39443010e-01,  8.51549134e-02, -4.31577228e-02,\n",
      "         3.84293236e-02, -1.57063112e-01,  9.57396552e-02,\n",
      "         9.45753902e-02,  3.17196250e-02, -1.22113638e-02,\n",
      "        -1.30302578e-01,  5.03041819e-02,  8.47322866e-02,\n",
      "         1.08313456e-01, -1.15203492e-01, -9.02616903e-02,\n",
      "        -2.71189418e-02, -1.44308824e-02, -3.18381302e-02,\n",
      "        -1.55520812e-01, -4.69073327e-03, -6.55276850e-02,\n",
      "        -7.41751119e-02,  1.48896128e-01,  9.32623446e-02,\n",
      "         9.49777737e-02,  2.93031875e-02, -2.00845730e-02,\n",
      "         1.46387622e-01, -2.83303466e-02,  2.12298967e-02,\n",
      "         6.96459413e-02,  1.46831886e-03,  8.44548196e-02,\n",
      "         1.39923796e-01, -2.42621638e-02,  1.51069865e-01,\n",
      "         7.94474632e-02,  8.75578672e-02,  1.89642012e-02,\n",
      "        -1.14811701e-03,  2.09498443e-02, -1.63586423e-01,\n",
      "         4.59182709e-02,  1.47971651e-02,  7.90853500e-02,\n",
      "         1.85342625e-01, -9.25827324e-02,  5.30714877e-02,\n",
      "        -7.17204809e-02, -9.08936039e-02, -1.14940461e-02,\n",
      "        -7.50101134e-02,  6.95423558e-02, -9.21198912e-03,\n",
      "         1.04529850e-01,  1.51511533e-02, -1.88568175e-01,\n",
      "         1.53055489e-01,  1.49205670e-01,  9.97151285e-02,\n",
      "         1.13232791e-01,  8.32295790e-03, -1.37445303e-02,\n",
      "         1.11371972e-01, -1.35356054e-01,  6.15275986e-02,\n",
      "         1.21513465e-02, -1.53571829e-01, -6.36402220e-02,\n",
      "        -4.22563888e-02, -4.51189987e-02, -3.67010124e-02,\n",
      "         5.41536175e-02,  3.42860334e-02, -1.01113439e-01,\n",
      "         3.76000702e-02, -1.43716782e-01, -1.41901717e-01,\n",
      "         8.25325176e-02, -7.90598467e-02,  2.50857379e-02,\n",
      "        -1.15399798e-02, -2.50552641e-03,  8.08474123e-02,\n",
      "         7.85957798e-02,  6.80777729e-02, -3.34682092e-02,\n",
      "         2.86774081e-03, -3.06447851e-03, -6.33167550e-02,\n",
      "         9.81628820e-02, -1.34079561e-01,  4.55313437e-02,\n",
      "         3.12404186e-02, -1.06388442e-01,  5.45675121e-02,\n",
      "        -8.72560740e-02,  8.32289904e-02,  1.31589407e-03,\n",
      "         1.19337253e-01, -1.26412004e-01,  1.35655090e-01,\n",
      "        -6.64382279e-02,  1.16758905e-01, -1.14202015e-01,\n",
      "         1.30017385e-01,  8.36315379e-02, -1.01922117e-01,\n",
      "         3.90725993e-02, -1.54283643e-02,  9.42518637e-02,\n",
      "         2.24628728e-02, -2.96586212e-02,  5.45371175e-02,\n",
      "         1.50551721e-01,  1.25100598e-01,  6.04208894e-02,\n",
      "         5.42527102e-02, -3.92644107e-02,  7.47701451e-02,\n",
      "         1.85021143e-02, -1.98447984e-02, -1.96014807e-01,\n",
      "        -7.93355703e-02,  1.69316858e-01,  7.46083856e-02,\n",
      "        -7.63045400e-02, -4.86622266e-02,  4.95791845e-02,\n",
      "        -5.18125854e-02,  7.87326470e-02,  1.84640717e-02,\n",
      "         8.56713280e-02, -6.31565526e-02,  2.96097100e-02,\n",
      "        -1.10199703e-02,  1.69543073e-01,  5.78232370e-02,\n",
      "         7.85258934e-02, -8.50272179e-02,  8.01860467e-02,\n",
      "        -1.93555315e-03,  9.12717953e-02, -8.37666020e-02,\n",
      "        -1.08811490e-01,  8.26100782e-02,  1.17908359e-01,\n",
      "        -1.35939464e-01, -1.53679131e-02,  1.02485813e-01,\n",
      "         6.08024076e-02, -1.14007674e-01, -8.68219659e-02,\n",
      "         1.01605676e-01,  6.58709407e-02,  3.89500521e-02,\n",
      "        -1.89290792e-01,  8.45216960e-02,  1.92582875e-01,\n",
      "        -1.15105882e-01, -7.11243674e-02, -1.22028902e-01,\n",
      "        -1.46248892e-01, -1.53148845e-02, -4.06075381e-02,\n",
      "        -2.28697713e-02, -2.63764542e-02, -5.28691337e-03,\n",
      "         3.03271948e-03, -6.00598045e-02, -3.25005762e-02,\n",
      "         2.85903942e-02, -1.35702072e-02,  2.66128518e-02,\n",
      "        -9.04512331e-02,  1.56316265e-01, -4.34520207e-02,\n",
      "        -2.59020682e-02,  1.39910370e-01,  4.81463894e-02,\n",
      "         9.33461413e-02,  2.71578971e-02, -1.64020229e-02,\n",
      "        -4.88682231e-03,  1.63181707e-01, -5.06505324e-03,\n",
      "         3.68683599e-02, -4.98215891e-02, -4.16989475e-02,\n",
      "         1.88691661e-01, -1.34312600e-01,  7.31736943e-02,\n",
      "         9.85405669e-02, -4.58699949e-02,  3.80918011e-02,\n",
      "        -7.64490617e-03,  7.23583996e-02, -5.58341928e-02,\n",
      "        -3.33020613e-02, -8.46247599e-02,  6.16729213e-03,\n",
      "         9.97769684e-02,  9.04029384e-02,  1.23226112e-02,\n",
      "         2.60923128e-03,  3.65430154e-02, -1.87607612e-02,\n",
      "        -1.09575704e-01, -6.94839358e-02, -7.20398426e-02,\n",
      "         1.12895608e-01, -1.25200599e-01, -6.93718567e-02,\n",
      "        -1.58708468e-01,  8.63142777e-03,  3.69062386e-02,\n",
      "        -4.87179309e-02,  5.16567901e-02, -8.47267583e-02,\n",
      "         1.10515259e-01, -6.95575401e-02, -7.85614997e-02,\n",
      "         8.29219725e-03,  6.94115385e-02,  7.37996027e-02,\n",
      "         8.39593783e-02,  1.15927206e-02, -5.65260015e-02,\n",
      "         1.75401587e-02, -7.60566518e-02, -6.78057596e-02,\n",
      "        -1.61223318e-02, -8.69908258e-02,  5.21065407e-02,\n",
      "        -1.00275949e-01, -1.86921597e-01, -5.98783158e-02,\n",
      "         1.89855378e-02, -5.51523231e-02,  8.91817268e-03,\n",
      "        -1.02345727e-01, -7.93333650e-02,  1.00823157e-01,\n",
      "         1.73765779e-01,  4.22351575e-03, -7.46463910e-02,\n",
      "         7.42063969e-02,  1.64727136e-01,  2.59995740e-02,\n",
      "        -7.59294331e-02, -2.81787571e-02, -1.38967201e-01,\n",
      "        -1.51738346e-01,  1.24610802e-02,  1.51595073e-02,\n",
      "        -5.40920608e-02,  1.23735011e-01, -4.71561402e-02,\n",
      "        -4.89015393e-02,  1.65853426e-01, -5.40418290e-02,\n",
      "        -4.84404154e-02,  6.90304413e-02,  2.78428346e-02,\n",
      "         7.61643350e-02, -1.00644445e-02,  1.45399660e-01,\n",
      "        -1.26493415e-02,  4.89887856e-02,  1.59175828e-01,\n",
      "        -8.57538637e-03,  8.74507055e-02, -6.44844249e-02,\n",
      "         7.37160668e-02,  7.84379467e-02,  7.47814626e-02,\n",
      "         4.31328006e-02,  1.21706776e-01,  1.31794199e-01,\n",
      "         4.03295159e-02, -8.63203555e-02,  1.16605759e-02,\n",
      "         1.13486759e-01,  1.57229483e-01, -7.88313076e-02,\n",
      "         5.00571094e-02,  2.34038681e-02,  3.38241421e-02,\n",
      "         2.03014817e-02,  4.99236993e-02,  6.38200715e-02,\n",
      "         1.01808228e-01,  1.18343353e-01, -1.03004990e-04,\n",
      "        -5.29895201e-02,  5.53446896e-02, -1.25808612e-01,\n",
      "        -3.86212184e-03,  1.94902774e-02,  9.95056033e-02,\n",
      "         1.48898978e-02,  2.19385382e-02,  1.31483721e-02,\n",
      "         1.58326607e-02, -4.36816178e-02, -5.46552837e-02,\n",
      "        -5.09147830e-02, -5.88221895e-03, -9.54407379e-02,\n",
      "         4.83677052e-02,  8.92302766e-02,  9.59842056e-02,\n",
      "         2.98759248e-02,  8.05084035e-02,  1.90256432e-01,\n",
      "        -6.96957260e-02,  1.33622931e-02, -1.21796345e-02,\n",
      "         1.85814247e-01, -4.65932973e-02, -1.71238463e-02,\n",
      "        -8.06362852e-02,  3.78017835e-02,  8.02317169e-03,\n",
      "         7.72089362e-02,  2.37548556e-02,  7.85609335e-02,\n",
      "         8.26394781e-02, -1.52875977e-02,  4.88219224e-02,\n",
      "        -8.05908665e-02,  3.54684703e-02, -1.15979634e-01,\n",
      "         9.55907255e-03,  5.37435524e-02,  4.97053228e-02,\n",
      "        -1.50279269e-01, -1.72573045e-01,  7.54623041e-02,\n",
      "        -6.19554427e-03, -1.02941440e-02,  8.96713957e-02,\n",
      "         4.20442335e-02,  8.96891281e-02, -3.56450299e-04,\n",
      "         1.19331395e-02, -9.01147649e-02,  1.55392215e-01,\n",
      "         1.00133447e-02,  8.75619724e-02,  1.01505164e-02,\n",
      "        -8.73730108e-02,  7.63693526e-02, -1.20988702e-02,\n",
      "         2.22704699e-03,  5.60367107e-03,  1.77796688e-02,\n",
      "        -4.33131270e-02,  1.69056818e-01, -9.85448584e-02,\n",
      "         5.50251864e-02,  1.84889138e-02, -2.79322714e-02,\n",
      "        -2.12587956e-02,  7.61669725e-02,  4.83418517e-02,\n",
      "         1.79609224e-01, -5.38866296e-02,  7.43045425e-03,\n",
      "        -1.21083595e-01,  1.51750457e-04, -1.02433972e-01,\n",
      "         2.70435251e-02,  6.85446803e-03,  9.63955671e-02,\n",
      "         8.03290233e-02,  2.66577210e-02, -9.42205489e-02,\n",
      "         5.63910902e-02, -1.26290366e-01,  1.55319005e-01,\n",
      "        -7.00648054e-02, -1.55856296e-01, -5.55034354e-02,\n",
      "         9.35375765e-02, -5.78469932e-02,  3.29856612e-02,\n",
      "         9.52966735e-02, -1.81467533e-01,  1.18219040e-01,\n",
      "        -1.14591300e-01,  3.70181054e-02,  1.69293940e-01,\n",
      "        -6.03399985e-02,  1.64221466e-01,  7.79261300e-03,\n",
      "        -6.93012550e-02, -5.44922166e-02]], dtype=float32)>, <tf.Variable 'lstm_init_1:0' shape=(1, 512) dtype=float32, numpy=\n",
      "array([[-0.04383171,  0.02887756,  0.06267621, -0.096937  ,  0.1505087 ,\n",
      "         0.1096919 ,  0.03713658,  0.03537399, -0.03922427,  0.01556518,\n",
      "         0.01219525,  0.02177679, -0.14633648,  0.04602938,  0.05894841,\n",
      "         0.0410884 ,  0.08818587,  0.07438527,  0.0602199 , -0.12214692,\n",
      "         0.05726491,  0.04351493, -0.08866259,  0.05832009, -0.04279665,\n",
      "         0.01288899,  0.06849023,  0.1516915 , -0.00332719,  0.1652125 ,\n",
      "        -0.16673861, -0.00153987, -0.02132472,  0.1850957 ,  0.07701167,\n",
      "        -0.07852316,  0.18273877, -0.10224327,  0.08773478,  0.17084117,\n",
      "         0.08006684,  0.17836897,  0.03861497, -0.11442363,  0.03988605,\n",
      "        -0.10848004,  0.0687951 ,  0.11230498, -0.19230951,  0.01754939,\n",
      "         0.05432945, -0.13846573, -0.02244483,  0.07324781,  0.05414937,\n",
      "         0.01909482, -0.03010473,  0.07627083, -0.045394  ,  0.14739595,\n",
      "        -0.05199789,  0.06576998,  0.01103988,  0.02451523,  0.00075497,\n",
      "         0.17124344, -0.11116562, -0.03768408, -0.0132871 ,  0.0561446 ,\n",
      "        -0.00242983, -0.07444116,  0.07237487, -0.07148085,  0.04151497,\n",
      "        -0.06946079, -0.16534035, -0.04540069,  0.04449611,  0.10472721,\n",
      "         0.06953108, -0.04283316, -0.08170811,  0.1030397 ,  0.11026806,\n",
      "        -0.06229142, -0.14171477, -0.0661201 ,  0.02938643, -0.02593789,\n",
      "         0.02315402, -0.07408974,  0.11138768, -0.02804732,  0.07451991,\n",
      "        -0.10816073, -0.09320692,  0.17507778, -0.08680965,  0.0412483 ,\n",
      "         0.07857969, -0.01389117,  0.07996373, -0.0076712 , -0.05175992,\n",
      "        -0.02263649,  0.05075603,  0.01404383, -0.09467851,  0.0402476 ,\n",
      "        -0.06260955, -0.10868283, -0.11387274,  0.08883422, -0.16849601,\n",
      "         0.18174258, -0.07241659,  0.11398059, -0.02673709, -0.15881641,\n",
      "         0.02269921, -0.03955144,  0.09912767,  0.1743515 , -0.04795614,\n",
      "        -0.03316797, -0.08514652,  0.12917598, -0.02280388,  0.18016122,\n",
      "         0.02433882,  0.03205115,  0.1519001 , -0.12404325,  0.06381001,\n",
      "         0.09674432, -0.00209263,  0.07017969, -0.0465623 ,  0.16460526,\n",
      "        -0.13111086, -0.17130984, -0.02476877, -0.07374182,  0.07315803,\n",
      "         0.07474729,  0.04756759,  0.15457828, -0.06704557,  0.01142764,\n",
      "         0.09083721,  0.00605474,  0.0470715 ,  0.12725823, -0.01705048,\n",
      "        -0.02602098,  0.01790543, -0.04844193,  0.01530494,  0.03465532,\n",
      "        -0.07907736, -0.12609313,  0.02739532,  0.04688986, -0.09209361,\n",
      "        -0.09495843,  0.19759102,  0.03884301,  0.10095848, -0.07383445,\n",
      "        -0.08591624, -0.14237617,  0.19820708, -0.07575951, -0.0878237 ,\n",
      "        -0.00689013,  0.00704315, -0.02923789, -0.16037008,  0.04944556,\n",
      "        -0.18597297, -0.00561232,  0.10373326, -0.01127333, -0.11529195,\n",
      "         0.03092986, -0.08853164,  0.02562257,  0.0988488 ,  0.06285712,\n",
      "        -0.01501237, -0.08080586, -0.00306589, -0.04102012, -0.01179121,\n",
      "         0.10085773,  0.09668471,  0.11877171,  0.00675585, -0.00647703,\n",
      "         0.14642464,  0.0598534 , -0.11478881, -0.15407619, -0.05993337,\n",
      "         0.1348524 , -0.06130053, -0.14727263,  0.08147   , -0.07196605,\n",
      "         0.08452241, -0.11537081,  0.12854289, -0.06346655, -0.04221925,\n",
      "         0.04886898, -0.07496509,  0.0056879 , -0.04033034,  0.08628651,\n",
      "         0.01732027, -0.0961089 , -0.00274148,  0.01455483, -0.10666499,\n",
      "         0.10682907,  0.04240119, -0.06654938, -0.06047506,  0.14944948,\n",
      "        -0.14471634,  0.09029984, -0.0072301 ,  0.09636119, -0.16334566,\n",
      "        -0.04973344,  0.02152348, -0.09463545,  0.02136835, -0.10955669,\n",
      "         0.00815023,  0.16695562, -0.02323917, -0.00628776,  0.09023791,\n",
      "         0.00807548,  0.02159339,  0.04339286, -0.03327078, -0.03822922,\n",
      "         0.0472961 , -0.18340425, -0.01718955, -0.0223506 , -0.01239752,\n",
      "        -0.0125558 , -0.06856903,  0.0063274 , -0.1854266 ,  0.10379968,\n",
      "        -0.03825486,  0.08259597, -0.03712935, -0.05116443, -0.00680937,\n",
      "         0.03170696, -0.04276922, -0.14276204, -0.00142576,  0.04278125,\n",
      "        -0.1452315 , -0.04975073,  0.06116049, -0.01711962,  0.05242457,\n",
      "        -0.05704934, -0.01092872,  0.0292249 , -0.00955954, -0.00768014,\n",
      "        -0.08500655,  0.01031311, -0.132207  ,  0.0331573 ,  0.14710197,\n",
      "         0.13901971, -0.08017548,  0.03564948, -0.07577182, -0.00156537,\n",
      "        -0.07300379,  0.10730246, -0.06059561, -0.07481581, -0.13045721,\n",
      "        -0.05175999,  0.08779325, -0.06540339, -0.03644661, -0.15627268,\n",
      "        -0.13486609, -0.09231745,  0.10434587, -0.07688453, -0.02513257,\n",
      "         0.01991736,  0.07188585, -0.001197  ,  0.07807165, -0.04552909,\n",
      "         0.01653995,  0.00714078,  0.13034983,  0.10989501, -0.06756873,\n",
      "        -0.07208421, -0.07166634,  0.04505247, -0.07661497,  0.12685685,\n",
      "        -0.04927582, -0.06025551,  0.08917729, -0.1292146 , -0.12222462,\n",
      "         0.10067844,  0.10342282,  0.13097005, -0.12423581, -0.07106411,\n",
      "        -0.02486465,  0.05197416,  0.00864822, -0.05764779, -0.07185112,\n",
      "         0.13307206,  0.06963232,  0.05155478, -0.10608798,  0.06644727,\n",
      "         0.09596545, -0.13349484,  0.01724999, -0.02962191,  0.04374793,\n",
      "         0.01925968,  0.06278142, -0.00519387,  0.07344957, -0.03913873,\n",
      "         0.05088852,  0.07323107,  0.12214001, -0.02857219, -0.06594101,\n",
      "        -0.05337643, -0.03209942,  0.04206588,  0.09735247,  0.07034087,\n",
      "        -0.06410839, -0.09174951, -0.03822979,  0.13673715, -0.06497754,\n",
      "         0.04150238,  0.05937195,  0.07480889,  0.07111589, -0.04882757,\n",
      "        -0.1446401 ,  0.06592845, -0.15892224, -0.02325759,  0.11784234,\n",
      "         0.02631853,  0.02340258,  0.04972157, -0.1771208 ,  0.11925837,\n",
      "         0.0331258 ,  0.09059093, -0.09982771,  0.0762016 ,  0.18290608,\n",
      "        -0.00844568, -0.06367657,  0.0894151 ,  0.14174901,  0.01127527,\n",
      "        -0.0111511 ,  0.15325539, -0.04717607, -0.03541177,  0.01044826,\n",
      "        -0.01026122, -0.13003857,  0.04101593,  0.02585368, -0.12484644,\n",
      "         0.06455145,  0.08987294,  0.00145047,  0.04152731, -0.12300377,\n",
      "        -0.1243235 ,  0.05853758,  0.18048088,  0.05124713, -0.09610285,\n",
      "         0.11830357,  0.04994806,  0.05986258, -0.05262817,  0.0250775 ,\n",
      "         0.01411724,  0.01868468, -0.02146756,  0.02483287, -0.12269533,\n",
      "         0.03711169, -0.11117283, -0.02625429,  0.05302743,  0.09437735,\n",
      "        -0.00900837,  0.169721  , -0.08860298, -0.14275728, -0.04392468,\n",
      "         0.07642617,  0.14558358,  0.13608466,  0.10220134, -0.04780946,\n",
      "        -0.08807267, -0.19114344,  0.06490749,  0.01346005, -0.19923918,\n",
      "        -0.09467854,  0.10635443,  0.07448954, -0.09079473, -0.18862863,\n",
      "         0.04020469, -0.08031979,  0.0680473 , -0.04194263,  0.0835102 ,\n",
      "         0.06732541, -0.09217023, -0.08756384,  0.14409886, -0.09561062,\n",
      "        -0.00583811,  0.12166017,  0.13168924,  0.09606896,  0.06046114,\n",
      "        -0.05658428,  0.1981233 , -0.02582342, -0.01432561, -0.03013311,\n",
      "        -0.01717431,  0.09517317,  0.03450646, -0.08375617,  0.03629416,\n",
      "        -0.04639343,  0.03949042, -0.11064601, -0.03944082,  0.05673062,\n",
      "         0.11221298, -0.1579328 , -0.00669318,  0.16956185,  0.10958071,\n",
      "         0.10575465, -0.00739248, -0.16493645, -0.1321582 , -0.05594935,\n",
      "        -0.14373   ,  0.04259301,  0.04347656, -0.03482347, -0.06934328,\n",
      "        -0.13873611,  0.12708311, -0.12478252,  0.07635798, -0.00283226,\n",
      "        -0.08062107, -0.03433154, -0.11726693, -0.02019282, -0.07533749,\n",
      "        -0.09300837, -0.04189991, -0.19787768,  0.04723939, -0.03619519,\n",
      "         0.04059938, -0.08563868,  0.06606738,  0.00406797, -0.00635254,\n",
      "         0.08053971, -0.00871777]], dtype=float32)>]\n",
      "Restored from ../tf_ckpts/word_sv_agreement_lm/lm_lstm_shared_emb_em-512_h-512_d-2_hdrop-0.3_indrop-0.0_lstm_drop30_v2_0.001_nol2_batchsumloss/ckpt-60\n"
     ]
    }
   ],
   "source": [
    "model_config = 'lstm_drop30_v2'\n",
    "model_name = 'lm_lstm_shared_emb'\n",
    "train_config ='radam_fast'\n",
    "# Create the Model\n",
    "model_params = get_model_params(task,model_name, model_config)\n",
    "print(\"model_params: \", model_params.__dict__)\n",
    "\n",
    "model = MODELS[model_name](hparams=get_model_params(task,model_name, model_config))\n",
    "\n",
    "trainer_params = get_train_params(train_config)\n",
    "\n",
    "log_dir = os.path.join(log_dir,task.name, model.model_name+\"_\"+str(model_config)+\"_\"+str(trainer_params.learning_rate)+\"_\"+exp_name)\n",
    "ckpt_dir = os.path.join(chkpt_dir,task.name, model.model_name+\"_\"+str(model_config)+\"_\"+str(trainer_params.learning_rate)+\"_\"+exp_name)\n",
    "\n",
    "print(log_dir)\n",
    "\n",
    "trainer = Trainer(task=task,\n",
    "                model=model,\n",
    "                train_params=get_train_params('radam_fast'),\n",
    "                log_dir=log_dir,\n",
    "                ckpt_dir=ckpt_dir)\n",
    "\n",
    "trainer.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function accuracy_topk at 0x7fb953c86b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function accuracy_topk at 0x7fb953c86b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function accuracy_topk at 0x7fb953c86b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function accuracy_topk at 0x7fb953c86b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 7s 72ms/step - loss: 4.4992 - batch_masked_sequence_loss: 4.4992 - masked_batch_perplexity: 90.3702 - masked_perplexity: 128.5419 - accuracy: 0.0600 - accuracy_top2: 0.0804 - accuracy_top5: 0.1069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.499240121841431,\n",
       " 4.49924,\n",
       " 90.37023,\n",
       " 128.54193,\n",
       " 0.06004137,\n",
       " 0.080423586,\n",
       " 0.10690875]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.evaluate(task.test_dataset, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "(64, 50, 10036)\n",
      "(3200, 10036)\n",
      "(3200, 1)\n",
      "<tensorflow.python.eager.def_function.Function object at 0x7fb953c82950>\n",
      "tf.Tensor(4.362302, shape=(), dtype=float32)\n",
      "tf.Tensor(4.362302, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in task.test_dataset:\n",
    "    print(len(x))\n",
    "    mask = tf.cast(y > 0, dtype=tf.float32)\n",
    "    logits = model(x)\n",
    "    print(logits.shape)\n",
    "    logits = tf.reshape(logits, (-1, logits.shape[-1]))\n",
    "    targets = tf.reshape(y, (-1, 1))\n",
    "    mask = tf.reshape(mask, (-1, 1))\n",
    "    correct = tf.cast(tf.argmax(model(x), axis=-1) == y, dtype=tf.float32)\n",
    "    print(logits.shape)\n",
    "    print(targets.shape)\n",
    "    print(model.loss)\n",
    "    print(model.loss(y_pred=logits, y_true=targets))\n",
    "    print(tf.reduce_sum(masked_sequence_loss(y_pred=logits, y_true=targets)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_inflect_from_vocab(vocab_file, freq_threshold=1000):\n",
    "    vbp = {}\n",
    "    vbz = {}\n",
    "    nn = {}\n",
    "    nns = {}\n",
    "    from_pos = {'NNS': nns, 'NN': nn, 'VBP': vbp, 'VBZ': vbz}\n",
    "\n",
    "    for line in open(vocab_file):\n",
    "        if line.startswith(' '):   # empty string token\n",
    "            continue\n",
    "        word, pos, count = line.strip().split()\n",
    "        count = int(count)\n",
    "        if len(word) > 1 and pos in from_pos and count >= freq_threshold:\n",
    "            from_pos[pos][word] = count\n",
    "\n",
    "    verb_infl = {'VBP': 'VBZ', 'VBZ': 'VBP'}\n",
    "    for word, count in vbz.items():\n",
    "        candidate = infl_eng.plural_verb(word)\n",
    "        if candidate in vbp:\n",
    "            verb_infl[candidate] = word\n",
    "            verb_infl[word] = candidate\n",
    "\n",
    "    noun_infl = {'NN': 'NNS', 'NNS': 'NN'}\n",
    "    for word, count in nn.items():\n",
    "        candidate = infl_eng.plural_noun(word)\n",
    "        if candidate in nns:\n",
    "            noun_infl[candidate] = word\n",
    "            noun_infl[word] = candidate\n",
    "\n",
    "    return verb_infl, noun_infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import inflect\n",
    "\n",
    "infl_eng = inflect.engine()\n",
    "\n",
    "dependency_fields = ['sentence', 'orig_sentence', 'pos_sentence',\n",
    "                     'subj', 'verb', 'subj_pos', 'has_rel', 'has_nsubj',\n",
    "                     'verb_pos', 'subj_index', 'verb_index', 'n_intervening',\n",
    "                     'last_intervening', 'n_diff_intervening', 'distance',\n",
    "                     'max_depth', 'all_nouns', 'nouns_up_to_verb']\n",
    "\n",
    "verb_infl, noun_infl = gen_inflect_from_vocab('wiki.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "1it [00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "2it [00:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "4it [00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 10 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 10 calls to <function LmLSTMSharedEmb.call at 0x7fb93c36e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "688it [12:58,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "distance_hits = Counter()\n",
    "distance_total = Counter()\n",
    "diff_hits = Counter()\n",
    "diff_total = Counter()\n",
    "\n",
    "test_data = task.databuilder.as_dataset(split='test', batch_size=1000)\n",
    "e = 0\n",
    "for example in tqdm(test_data):\n",
    "    e += 1\n",
    "    encoded_sentences = example['sentence']\n",
    "    s_shape = tf.shape(encoded_sentences)\n",
    "    batch_size, length = s_shape[0], s_shape[1]\n",
    "    bos = tf.ones((batch_size,1), dtype=tf.int64) * task.databuilder.sentence_encoder().encode(constants.bos)\n",
    "    eos = tf.ones((batch_size,1), dtype=tf.int64) * task.databuilder.sentence_encoder().encode(constants.eos)\n",
    "\n",
    "    encoded_sentences = tf.concat([bos, encoded_sentences, eos], axis=1)\n",
    "    \n",
    "    actual_verbs = example['verb']\n",
    "    inflected_verbs = [verb_infl[v.decode(\"utf-8\")] for v in actual_verbs.numpy()]\n",
    "    verb_indexes = example['verb_position'] - 1\n",
    "    distances = example['distance'].numpy()\n",
    "    nz = example['n_intervening'].numpy()\n",
    "    n_diffs = example['n_diff_intervening'].numpy()\n",
    "    \n",
    "    sentence =  task.databuilder.sentence_encoder().decode(encoded_sentences[0])\n",
    "    actual_verb_indexes = [task.databuilder.sentence_encoder().encode(v)[0] for v in actual_verbs.numpy()]\n",
    "    inflected_verb_indexes = [task.databuilder.sentence_encoder().encode(v)[0] for v in inflected_verbs]\n",
    "\n",
    "    \n",
    "    scores = model(encoded_sentences)\n",
    "    actual_batch_indexes = [ (i,verb_indexes[i], actual_verb_indexes[i]) for i in range(len(verb_indexes))]\n",
    "    actual_scores = tf.compat.v2.gather_nd(scores, actual_batch_indexes)\n",
    "\n",
    "    inflected_batch_indexes = [ (i,verb_indexes[i], inflected_verb_indexes[i]) for i in range(len(verb_indexes))]\n",
    "    infelected_scores = tf.compat.v2.gather_nd(scores, inflected_batch_indexes)\n",
    "    \n",
    "    corrects = actual_scores > infelected_scores\n",
    "    for i, c in enumerate(corrects):\n",
    "        if verb_indexes[i] == 10035:\n",
    "            continue\n",
    "        if nz[i] > 4 or distances[i] > 16:\n",
    "            continue\n",
    "            \n",
    "        distance_total[distances[i]] += 1\n",
    "        distance_hits[distances[i]] += int(c)\n",
    "        if nz[i] == n_diffs[i]:\n",
    "            n = nz[i]\n",
    "            diff_total[n] += 1\n",
    "            diff_hits[n] += int(c)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by distance\n",
      "1 | 0.72 926851\n",
      "2 | 0.91 86574\n",
      "3 | 0.79 71319\n",
      "4 | 0.84 107576\n",
      "5 | 0.87 59136\n",
      "6 | 0.84 37045\n",
      "7 | 0.83 28371\n",
      "8 | 0.82 20879\n",
      "9 | 0.81 14993\n",
      "10 | 0.80 11346\n",
      "11 | 0.79 8800\n",
      "12 | 0.79 6395\n",
      "13 | 0.77 4950\n",
      "14 | 0.76 3576\n",
      "15 | 0.75 2629\n",
      "16 | 0.74 2001\n",
      "Accuracy by intervenings\n",
      "0 | 0.74 1133182\n",
      "1 | 0.78 51596\n",
      "2 | 0.79 9045\n",
      "3 | 0.75 1828\n",
      "4 | 0.71 460\n"
     ]
    }
   ],
   "source": [
    "dis_acc = {}\n",
    "dis_acc = np.zeros(17)\n",
    "dif_acc = np.zeros(5)\n",
    "print('Accuracy by distance')\n",
    "for k in sorted(distance_hits.keys()):\n",
    "    v = distance_hits[k]\n",
    "    acc = v / distance_total[k]\n",
    "    dis_acc[k] = acc\n",
    "    print(\"%d | %.2f\" % (k, acc), distance_total[k])\n",
    "\n",
    "print('Accuracy by intervenings')\n",
    "for k in sorted(diff_hits.keys()):\n",
    "    v = diff_hits[k]\n",
    "    acc = v * 1./diff_total[k]\n",
    "    print(\"%d | %.2f\" % (k, acc), diff_total[k])\n",
    "    dif_acc[k] = acc\n",
    "\n",
    "stats = {'distance': dis_acc, 'intervenings': dif_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10035]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.databuilder.sentence_encoder().encode(\"unk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-886f261e37cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "d = dis_acc\n",
    "lists = sorted(d.items()) # sorted by key, return a list of tuples\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

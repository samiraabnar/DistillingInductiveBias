#!/bin/bash

#SBATCH --job-name=offline_distill_lm
#SBATCH --time=20:00:00
#SBATCH --partition=gpu_shared
#SBATCH --gres=gpu:1
#SBATCH --mem=60G

module load 2019
module load CUDA/10.0.130
module load cuDNN/7.6.3-CUDA-10.0.130

source ~/anaconda3/etc/profile.d/conda.sh
conda init
conda activate indist

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/sw/arch/Debian9/EB_production/2019/software/CUDA/10.0.130/extras/CUPTI/lib64/


HEAD_DIR="/home/samigpu/Codes/InDist"
CODE_DIR=$HEAD_DIR/
DATA_DIR=$HEAD_DIR/data
LOGS_DIR=$HEAD_DIR/logs

export PYTHONPATH=$PYTHONPATH:$HEAD_DIR

# 0.001_lisa_crs_slw_offlineteacher_v10
# 120 121 122
# 200 201 292

# 0.001_lisa_offlineteacher_v3
# 220 221 222 small
# 225, 226, 227 big

# 0.001_lisa_crs_fst_offlineteacher_v20
# 420 421 422 small
# 425, 426, 427 big


# 0.001_lisa_crs_fst_offlineteacher_v22
# 520 521 522 small
# 525, 526, 527 big

CUDA_VISIBLE_DEVICES=0 python $CODE_DIR/distill/distill_main.py --task=word_sv_agreement_lm \
--teacher_model=lm_lstm_shared_emb \
--teacher_exp_name=0.001_lisa_crs_fst_offlineteacher_v22 \
--student_model=lm_lstm_shared_emb \
--student_exp_name=lisa_fd521 \
--teacher_config=biglstm_drop31_v2 \
--student_config=lstm_drop31_v2 \
--distill_mode=offline \
--distill_config=pure_dstl_4_crs_slw

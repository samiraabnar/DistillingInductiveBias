#!/bin/bash

#SBATCH --job-name=offline_distill_lm
#SBATCH --time=20:00:00
#SBATCH --partition=gpu_shared
#SBATCH --gres=gpu:1
#SBATCH --mem=60G

module load 2019
module load CUDA/10.0.130
module load cuDNN/7.6.3-CUDA-10.0.130

source ~/anaconda3/etc/profile.d/conda.sh
conda init
conda activate indist

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/sw/arch/Debian9/EB_production/2019/software/CUDA/10.0.130/extras/CUPTI/lib64/


HEAD_DIR="/home/samigpu/Codes/InDist"
CODE_DIR=$HEAD_DIR/
DATA_DIR=$HEAD_DIR/data
LOGS_DIR=$HEAD_DIR/logs

export PYTHONPATH=$PYTHONPATH:$HEAD_DIR

gpt2
# 110, 111, 112 0.001_samira_offlineteacher_v11
# 115, 116, 117 0.001_samira_offlineteacher_v5

gpt2_shared
# 200, 201, 202 0.001_samira_offlineteacher_v10
# 205, 206, 207 0.001_samira_offlineteacher_v11

CUDA_VISIBLE_DEVICES=0 python $CODE_DIR/distill/distill_main.py \
--task=word_sv_agreement_vp \
--teacher_model=cl_gpt2_shared \
--teacher_exp_name=0.001_samira_offlineteacher_v10 \
--student_model=cl_lstm \
--student_exp_name=lisa_fd200 \
--teacher_config=small_gpt_v9 \
--student_config=small_lstm_v4 \
--distill_mode=offline \
--distill_config=dstl_6_crs_slw
